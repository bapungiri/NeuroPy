{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal bias maze vs remaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import subjects\n",
    "\n",
    "sessions = subjects.nsd.re_maze + subjects.sd.re_maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import ExplainedVariance\n",
    "import pingouin as pg\n",
    "from neuropy.utils.neurons_util import calculate_neurons_ccg\n",
    "\n",
    "bias_df = []\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "    pre = sess.paradigm[\"pre\"].flatten()\n",
    "    maze = sess.paradigm[\"maze\"].flatten()\n",
    "    remaze = sess.paradigm[\"re-maze\"].flatten()\n",
    "\n",
    "    neurons = sess.neurons.get_neuron_type(\"pyr\")\n",
    "    wave_similarity = neurons.get_waveform_similarity()\n",
    "    pairs_bool = wave_similarity < 0.8  # only pairs which are least similar\n",
    "\n",
    "    get_bias = lambda epoch: calculate_neurons_ccg(\n",
    "        neurons.time_slice(epoch[0], epoch[1])\n",
    "    )\n",
    "\n",
    "    pre_bias = get_bias(pre)\n",
    "    maze_bias = get_bias(maze)\n",
    "    remaze_bias = get_bias(remaze)\n",
    "\n",
    "    bias_df.append(\n",
    "        pd.DataFrame(\n",
    "            dict(pre=pre_bias, maze=maze_bias, remaze=remaze_bias, grp=sess.tag)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "bias_df = pd.concat(bias_df, ignore_index=True)\n",
    "subjects.GroupData().save(bias_df, \"remaze_temporal_bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "\n",
    "sns.lmplot(\n",
    "    data=bias_df,\n",
    "    x=\"maze\",\n",
    "    y=\"pre\",\n",
    "    hue=\"grp\",\n",
    "    palette=[\"#9C27B0\", \"#F06292\"],\n",
    "    # x_partial=\"pre\",\n",
    "    # y_partial=\"pre\",\n",
    "    scatter_kws={'s':8},\n",
    "    # col='grp',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example radon transform figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "from neuropy.analyses.decoders import radon_transform\n",
    "from hfuncs import radon_transform_gpu\n",
    "from time import time\n",
    "\n",
    "s = time()\n",
    "for i in range(100):\n",
    "    radon_transform(np.ones((50,10)))\n",
    "e = time()\n",
    "print(e-s)\n",
    "\n",
    "s = time()\n",
    "for i in range(5000):\n",
    "    radon_transform_gpu(np.ones((50,10)))\n",
    "e = time()\n",
    "print(e-s)\n",
    "\n",
    "\n",
    "# sess = subjects.nsd.ratUday2[0]\n",
    "\n",
    "# maze = sess.paradigm[\"maze\"].flatten()\n",
    "# post = sess.paradigm[\"post\"].flatten()\n",
    "# neurons = sess.neurons.get_neuron_type(neuron_type=\"pyr\")\n",
    "# pos = sess.maze\n",
    "# # pos.t_start = pos.t_start - 0.5\n",
    "# run = sess.run\n",
    "# pf = Pf1D(\n",
    "#     neurons=neurons,\n",
    "#     position=pos,\n",
    "#     speed_thresh=4,\n",
    "#     sigma=4,\n",
    "#     grid_bin=2,\n",
    "#     epochs=run,\n",
    "#     frate_thresh=1,\n",
    "# )\n",
    "# # np.random.default_rng().shuffle(pf.tuning_curves)\n",
    "# pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "# epochs = sess.pbe.time_slice(maze[0], maze[0]+500)\n",
    "# decode = Decode1d(\n",
    "#     neurons=pf_neurons, ratemap=pf, epochs=epochs, bin_size=0.02\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import cupy as cp\n",
    "from numpy.random import default_rng\n",
    "from neuropy.analyses.decoders import radon_transform\n",
    "from hfuncs import radon_transform_gpu\n",
    "from neuropy import plotting\n",
    "from scipy import stats\n",
    "from neuropy.utils.mathutil import min_max_scaler\n",
    "import time\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "n_posteriors = len(decode.posterior)\n",
    "posterior_ind = default_rng().integers(0,n_posteriors,n_posteriors)\n",
    "# posterior_ind = [382, 42, 131, 162, 287, 284, 127, 331, 294, 205]\n",
    "# posterior_ind =[189, 139, 180, 178, 188, 103, 158,  15, 123, 156]\n",
    "# posterior_ind= [ 7, 126, 114, 116, 115]\n",
    "arrs = [decode.posterior[i] for i in posterior_ind]\n",
    "len_arr = np.cumsum([_.shape[1] for _ in arrs])[:-1]\n",
    "zsc_tuning = stats.zscore(pf.tuning_curves,axis=1)\n",
    "sort_ind = np.argsort(np.argmax(zsc_tuning,axis=1))\n",
    "post_gpu = cp.asarray(np.hstack(arrs)) \n",
    "\n",
    "s = time.time()\n",
    "arrs_gpu = cp.hsplit(post_gpu,len_arr)\n",
    "for i, arr in enumerate(arrs_gpu):\n",
    "    \n",
    "    score, velocity, intercept = radon_transform_gpu(arr, dt=0.02, dx=2, neighbours=4)\n",
    "\n",
    "e = time.time()\n",
    "print(e-s)\n",
    "\n",
    "# s = time.time()\n",
    "# for i, arr in enumerate(arrs):\n",
    "#     t_start = epochs[posterior_ind[i]].flatten()[0]\n",
    "#     score, velocity, intercept = radon_transform(arr, dt=0.02, dx=2, neighbours=4)\n",
    "# e = time.time()\n",
    "# print(e-s)\n",
    "\n",
    "s = time.time()\n",
    "results = Parallel(n_jobs=5)(\n",
    "            delayed(radon_transform)(\n",
    "                epoch,\n",
    "                dt=0.02,\n",
    "                dx=2,\n",
    "                neighbours=4,\n",
    "            )\n",
    "            for epoch in arrs\n",
    "        )\n",
    "score, velocity, intercept = np.asarray(results).T\n",
    "e = time.time()\n",
    "print(e-s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from numpy.random import default_rng\n",
    "from neuropy.analyses.decoders import radon_transform_gpu,radon_transform\n",
    "from neuropy import plotting\n",
    "from scipy import stats\n",
    "from neuropy.utils.mathutil import min_max_scaler\n",
    "import time\n",
    "\n",
    "n_posteriors = len(decode.posterior)\n",
    "posterior_ind = default_rng().integers(0,n_posteriors,5)\n",
    "# posterior_ind = [382, 42, 131, 162, 287, 284, 127, 331, 294, 205]\n",
    "# posterior_ind =[189, 139, 180, 178, 188, 103, 158,  15, 123, 156]\n",
    "# posterior_ind= [ 7, 126, 114, 116, 115]\n",
    "arrs = [decode.posterior[i] for i in posterior_ind]\n",
    "\n",
    "_, axs = plt.subplots(2, 5,sharey='row',sharex='col')\n",
    "# axs = axs.reshape(-1)\n",
    "zsc_tuning = stats.zscore(pf.tuning_curves,axis=1)\n",
    "sort_ind = np.argsort(np.argmax(zsc_tuning,axis=1))\n",
    "\n",
    "s = time.time()\n",
    "for i, arr in enumerate(arrs):\n",
    "    # arr = min_max_scaler(arr,axis=0)\n",
    "    t_start = epochs[posterior_ind[i]].flatten()[0]\n",
    "\n",
    "    score, velocity, intercept = radon_transform_gpu(arr, dt=0.02, dx=2, neighbours=4)\n",
    "    # arr = np.apply_along_axis(np.convolve, axis=0, arr=arr, v=np.ones(2 * 4 + 1))\n",
    "    # t = np.arange(arr.shape[1]) * 0.02+t_start\n",
    "    # pos = np.arange(arr.shape[0]) * 2\n",
    "\n",
    "    # axs[0,i].pcolormesh(t, pos,arr, cmap=\"hot\")\n",
    "    # axs[0,i].plot(t, velocity * (t-t_start) + intercept, color=\"w\")\n",
    "    # axs[0,i].set_ylim([pos.min(), pos.max()])\n",
    "    # axs[0,i].set_title(score.round(2))\n",
    "\n",
    "    # plotting.plot_raster(pf_neurons[sort_ind].time_slice(t_start=t[0],t_stop=t[-1]),ax=axs[1,i],color='k')\n",
    "e = time.time()\n",
    "print(e-s)\n",
    "\n",
    "s = time.time()\n",
    "for i, arr in enumerate(arrs):\n",
    "    # arr = min_max_scaler(arr,axis=0)\n",
    "    t_start = epochs[posterior_ind[i]].flatten()[0]\n",
    "\n",
    "    score, velocity, intercept = radon_transform(arr, dt=0.02, dx=2, neighbours=4)\n",
    "    # arr = np.apply_along_axis(np.convolve, axis=0, arr=arr, v=np.ones(2 * 4 + 1))\n",
    "    # t = np.arange(arr.shape[1]) * 0.02+t_start\n",
    "    # pos = np.arange(arr.shape[0]) * 2\n",
    "\n",
    "    # axs[0,i].pcolormesh(t, pos,arr, cmap=\"hot\")\n",
    "    # axs[0,i].plot(t, velocity * (t-t_start) + intercept, color=\"w\")\n",
    "    # axs[0,i].set_ylim([pos.min(), pos.max()])\n",
    "    # axs[0,i].set_title(score.round(2))\n",
    "\n",
    "    # plotting.plot_raster(pf_neurons[sort_ind].time_slice(t_start=t[0],t_stop=t[-1]),ax=axs[1,i],color='k')\n",
    "e = time.time()\n",
    "print(e-s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "\n",
    "sessions = subjects.nsd.ratUday2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub, sess in enumerate(sessions):\n",
    "    maze = sess.paradigm[\"maze\"].flatten()\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    neurons = sess.neurons.get_neuron_type(neuron_type=\"pyr\")\n",
    "    pos = sess.maze\n",
    "    pos.t_start = pos.t_start - 0.5\n",
    "    # run = sess.run\n",
    "    pf = Pf1D(\n",
    "        neurons=neurons,\n",
    "        position=pos,\n",
    "        speed_thresh=5,\n",
    "        sigma=4,\n",
    "        grid_bin=2,\n",
    "        # epochs=run,\n",
    "        frate_thresh=1,\n",
    "    )\n",
    "    pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "    epochs = sess.pbe.time_slice(maze[0], maze[0]+500)\n",
    "    decode = Decode1d(\n",
    "        neurons=pf_neurons, ratemap=pf, epochs=epochs, bin_size=0.02, decode_margin=15,nlines=8000\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = decode.weighted_correlation(decode.posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# decode.plot_summary()\n",
    "plt.plot(r,decode.velocity,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfuncs import plot_in_bokeh\n",
    "import bokeh.plotting as bplot\n",
    "\n",
    "# bplot.output_file(subjects.figpath_sd/'test_wake_decoding.html')\n",
    "bplot.output_notebook()\n",
    "p = plot_in_bokeh(\n",
    "    x=epochs.starts / 3600,\n",
    "    y=decode.score,\n",
    "    img_arr=decode.posterior,\n",
    "    color_by=decode.score,\n",
    "    palette=\"jet\",\n",
    "    size=10,\n",
    ")\n",
    "# p.line(pos.time,pos.x/350 + 0.2,line_width=2,color='black')\n",
    "bplot.show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting decoding stats if calculated via script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "\n",
    "sessions = subjects.nsd.ratUday2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub,sess in enumerate(sessions):\n",
    "\n",
    "    replay_pbe= sess.replay_pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfuncs import plot_replay_in_bokeh\n",
    "import bokeh.plotting as bplot\n",
    "\n",
    "bplot.output_notebook()\n",
    "# bplot.output_file(subjects.figpath_sd/'test_wake_decoding.html')\n",
    "p = plot_replay_in_bokeh(sess.replay_pbe)\n",
    "\n",
    "# p.line(pos.time,pos.x/350 + 0.2,line_width=2,color='black')\n",
    "bplot.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signficant sequences histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "\n",
    "sessions = subjects.nsd.ratUday2 + subjects.sd.ratUday4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_df = []\n",
    "for sub, sess in enumerate(sessions):\n",
    "\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    replay_pbe = sess.replay_pbe.to_dataframe()\n",
    "    is_replay = replay_pbe.is_replay\n",
    "    velocity_bool = np.abs(replay_pbe.velocity.values)>100\n",
    "\n",
    "    sig_events = np.logical_and(is_replay,velocity_bool)\n",
    "    starts = replay_pbe.start.values[sig_events]\n",
    "    bins = np.arange(post[0], post[0] + 2 * 3600, 600)\n",
    "    hist_replay = np.histogram(starts, bins)[0]\n",
    "    replay_df.append(\n",
    "        pd.DataFrame(\n",
    "            {\"bins\": ((bins[:-1] - post[0])/3600).round(2), \"hist\": hist_replay, \"grp\": sess.tag}\n",
    "        )\n",
    "    )\n",
    "\n",
    "replay_df = pd.concat(replay_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plotting.Fig(grid=(2,2))\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "sns.barplot(data=replay_df,x='bins',y='hist',hue='grp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean replay score across all events as a function of time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "\n",
    "sessions = subjects.nsd.ratUday2 + subjects.sd.ratUday4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "replay_df = []\n",
    "for sub, sess in enumerate(sessions):\n",
    "\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    replay_pbe = sess.replay_pbe.to_dataframe()\n",
    "    starts = sess.replay_pbe.starts\n",
    "    replay_score = replay_pbe.score\n",
    "    bins = np.arange(post[0], post[0] + 2 * 3600, 600)\n",
    "\n",
    "    mean_score = stats.binned_statistic(starts, replay_score, bins=bins)[0]\n",
    "    replay_df.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"bins\": ((bins[:-1] - post[0]) / 3600).round(2),\n",
    "                \"hist\": mean_score,\n",
    "                \"grp\": sess.tag,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "replay_df = pd.concat(replay_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plotting.Fig(grid=(2,2))\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "sns.lineplot(data=replay_df,x='bins',y='hist',hue='grp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of replay scores and comparison with shuffled scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "\n",
    "sessions = subjects.nsd.ratUday2 + subjects.sd.ratUday4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "score_df = []\n",
    "for sub, sess in enumerate(sessions):\n",
    "\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    replay_pbe = sess.replay_pbe.to_dataframe()\n",
    "\n",
    "    starts = sess.replay_pbe.starts\n",
    "    replay_score = replay_pbe.score\n",
    "\n",
    "    shuffle_scores = sess.replay_pbe.metadata[\"shuffle_score\"].flatten()\n",
    "    shuffle_starts = np.repeat(starts, 200)\n",
    "    \n",
    "    bins = np.arange(2)*3600 + post[0]\n",
    "    replay_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Zt\":np.digitize(starts,bins),\n",
    "            \"starts\": starts,\n",
    "            \"score\": replay_score,\n",
    "            \"grp\": sess.tag,\n",
    "        }\n",
    "    )\n",
    "    shuffle_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Zt\":np.digitize(shuffle_starts,bins),\n",
    "            \"starts\": shuffle_starts,\n",
    "            \"score\": shuffle_scores,\n",
    "            \"grp\": f\"{sess.tag}_shuffle\",\n",
    "        }\n",
    "    )\n",
    "    score_df.append(pd.concat([replay_df,shuffle_df]))\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.replay_pbe.metadata['shuffle_score'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plotting.Fig(grid=(2,2))\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "sns.violinplot(data=score_df,x='Zt',y='score',hue='grp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay score distribution comparison in POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "\n",
    "sessions = subjects.nsd.pf_sess + subjects.sd.pf_sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from neuropy.core import Epoch\n",
    "from neuropy.utils.mathutil import min_max_scaler\n",
    "\n",
    "score_df = []\n",
    "dist_replay_df = []\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    neurons = sess.neurons.get_neuron_type(neuron_type=\"pyr\")\n",
    "    pos = sess.maze\n",
    "    # run = sess.run\n",
    "    pf = Pf1D(\n",
    "        neurons=neurons,\n",
    "        position=pos,\n",
    "        speed_thresh=5,\n",
    "        sigma=4,\n",
    "        grid_bin=2,\n",
    "        # epochs=run,\n",
    "        frate_thresh=1,\n",
    "    )\n",
    "    pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "    zts = np.array([0, 1, 2, 4, 5, 7])\n",
    "    starts = zts * 3600 + post[0]\n",
    "\n",
    "    epochs = []\n",
    "    for s, zt in zip(starts,zts):\n",
    "        epochs.append(\n",
    "            sess.pbe.time_slice(s, s + 3600).set_labels(f\"{zt+1}\").to_dataframe()\n",
    "        )\n",
    "\n",
    "    epochs = Epoch(pd.concat(epochs, ignore_index=True))\n",
    "\n",
    "    decode = Decode1d(\n",
    "        neurons=pf_neurons,\n",
    "        ratemap=pf,\n",
    "        epochs=epochs,\n",
    "        bin_size=0.02,\n",
    "        decode_margin=15,\n",
    "        nlines=5000,\n",
    "    )\n",
    "    jump_distance = [np.abs(np.diff(_)).mean() for _ in decode.decoded_position]\n",
    "    weighted_corr = decode.weighted_correlation(decode.posterior)\n",
    "\n",
    "    norm_pos=min_max_scaler(decode.ratemap.xbin_centers)\n",
    "    decoded_position_mean =np.nanmean(np.hstack(decode.posterior),axis=1)\n",
    "    pos_bins = np.linspace(0,1,50)\n",
    "    mean_pos = np.interp(pos_bins,norm_pos,decoded_position_mean) \n",
    "\n",
    "    df_dist = pd.DataFrame(\n",
    "        dict(\n",
    "            bins = pos_bins,\n",
    "            mean_pos = mean_pos,\n",
    "            name=sess.animal.name,\n",
    "            grp=sess.tag,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        dict(\n",
    "            score=decode.score,\n",
    "            velocity=decode.velocity,\n",
    "            jump_distance=jump_distance,\n",
    "            weighted_corr=weighted_corr,\n",
    "            epoch=epochs.labels,\n",
    "            name=sess.animal.name,\n",
    "            grp=sess.tag,\n",
    "        )\n",
    "    )\n",
    "    score_df.append(df)\n",
    "    dist_replay_df.append(df_dist)\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n",
    "dist_replay_df = pd.concat(dist_replay_df,ignore_index=True)\n",
    "\n",
    "subjects.GroupData().save(score_df, \"replay_post_score\")\n",
    "subjects.GroupData().save(dist_replay_df, \"replay_pos_distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "\n",
    "sns.violinplot(\n",
    "    data=score_df,\n",
    "    x=\"epoch\",\n",
    "    y=\"score\",\n",
    "    hue=\"grp\",\n",
    "    split=True,\n",
    "    inner=None,\n",
    "    scale=\"width\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding re-maze with maze template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "\n",
    "sessions = (\n",
    "    subjects.nsd.ratSday2\n",
    "    + subjects.nsd.ratVday1\n",
    "    + subjects.nsd.ratUday2\n",
    "    + subjects.sd.ratSday3\n",
    "    + subjects.sd.ratVday2\n",
    "    + subjects.sd.ratUday4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "score_df = []\n",
    "dist_replay_df=[]\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "    re_maze = sess.paradigm[\"re-maze\"].flatten()\n",
    "    neurons = sess.neurons.get_neuron_type(neuron_type=\"pyr\")\n",
    "    pos = sess.maze\n",
    "    # run = sess.run\n",
    "    pf = Pf1D(\n",
    "        neurons=neurons,\n",
    "        position=pos,\n",
    "        speed_thresh=5,\n",
    "        sigma=4,\n",
    "        grid_bin=2,\n",
    "        # epochs=run,\n",
    "        frate_thresh=1,\n",
    "    )\n",
    "    pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "    epochs = sess.pbe.time_slice(re_maze[0], re_maze[1])\n",
    "    decode = Decode1d(\n",
    "        neurons=pf_neurons,\n",
    "        ratemap=pf,\n",
    "        epochs=epochs,\n",
    "        bin_size=0.02,\n",
    "        decode_margin=15,\n",
    "        nlines=5000,\n",
    "    )\n",
    "    jump_distance = [np.abs(np.diff(_)).mean() for _ in decode.decoded_position]\n",
    "\n",
    "    norm_pos=min_max_scaler(decode.ratemap.xbin_centers)\n",
    "    decoded_position_mean =np.nanmean(np.hstack(decode.posterior),axis=1)\n",
    "    pos_bins = np.linspace(0,1,50)\n",
    "    mean_pos = np.interp(pos_bins,norm_pos,decoded_position_mean) \n",
    "\n",
    "    df_dist = pd.DataFrame(\n",
    "        dict(\n",
    "            bins = pos_bins,\n",
    "            mean_pos = mean_pos,\n",
    "            name=sess.animal.name,\n",
    "            grp=sess.tag,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        dict(\n",
    "            score=decode.score,\n",
    "            velocity=decode.velocity,\n",
    "            jump_distance=jump_distance,\n",
    "            epoch=\"re-maze\",\n",
    "            name=sess.animal.name,\n",
    "            grp=sess.tag,\n",
    "        )\n",
    "    )\n",
    "    score_df.append(df)\n",
    "    dist_replay_df.append(df_dist)\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n",
    "dist_replay_df=  pd.concat(dist_replay_df, ignore_index=True)\n",
    "subjects.GroupData().save(score_df,'replay_re_maze_score')\n",
    "subjects.GroupData().save(dist_replay_df,'replay_re_maze_position_distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "\n",
    "sns.violinplot(\n",
    "    data=score_df,\n",
    "    x=\"epoch\",\n",
    "    y=\"score\",\n",
    "    hue=\"grp\",\n",
    "    split=True,\n",
    "    inner=None,\n",
    "    scale=\"width\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding theta sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "\n",
    "sessions = subjects.nsd.ratUday2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub, sess in enumerate(sessions):\n",
    "    maze = sess.paradigm[\"maze\"]\n",
    "    post = sess.paradigm[\"post\"]\n",
    "    neurons = sess.neurons.get_neuron_type(neuron_type=\"pyr\")\n",
    "    pos = sess.lin_maze\n",
    "    # pos.t_start = pos.t_start +0.5\n",
    "    run = sess.run\n",
    "    pf = Pf1D(\n",
    "        neurons=neurons,\n",
    "        position=pos,\n",
    "        speed_thresh=4,\n",
    "        sigma=4,\n",
    "        grid_bin=2,\n",
    "        # epochs=run,\n",
    "        frate_thresh=1,\n",
    "    )\n",
    "    pf_neurons = neurons.get_by_id(pf.ratemap.neuron_ids)\n",
    "    epochs = sess.pbe.time_slice(maze[0], maze[1])\n",
    "    decode = Decode1d(\n",
    "        neurons=pf_neurons, ratemap=pf.ratemap, epochs=epochs, bin_size=0.02,slideby=0.01\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfuncs import plot_in_bokeh\n",
    "import bokeh.plotting as bplot\n",
    "\n",
    "# bplot.output_file(subjects.figpath_sd/'test_wake_decoding.html')\n",
    "bplot.output_notebook()\n",
    "p = plot_in_bokeh(x=epochs.starts/3600 - sess.paradigm['maze'][0]/3600,y=decode.score,img_arr=decode.spkcount,color_by=decode.score,palette='jet_r',size=10)\n",
    "# p.line(pos.time,pos.x/350 + 0.2,line_width=2,color='black')\n",
    "bplot.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scratch code for pooled randon transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = [_.shape[1] for _ in decode.posterior[:60]]\n",
    "post = np.hstack(decode.posterior[:60])\n",
    "arr = post\n",
    "nlines=10000\n",
    "dt=1\n",
    "dx=1\n",
    "neighbours=1\n",
    "t = np.concatenate([np.arange(0,_) for _ in nbins])\n",
    "max_t = max(nbins)\n",
    "nt = len(t)\n",
    "tmid = (nt + 1) / 2 - 1\n",
    "\n",
    "pos = np.arange(arr.shape[0])\n",
    "npos = len(pos)\n",
    "pmid = (npos + 1) / 2 - 1\n",
    "\n",
    "# using convolution to sum neighbours\n",
    "arr = np.apply_along_axis(\n",
    "    np.convolve, axis=0, arr=arr, v=np.ones(2 * neighbours + 1), mode=\"same\"\n",
    ")\n",
    "\n",
    "# exclude stationary events by choosing phi little below 90 degree\n",
    "# NOTE: angle of line is given by (90-phi), refer Kloosterman 2012\n",
    "phi = np.random.uniform(low=-np.pi / 2, high=np.pi / 2, size=nlines)\n",
    "diag_len = np.sqrt((max_t - 1) ** 2 + (npos - 1) ** 2)\n",
    "rho = np.random.uniform(low=-diag_len / 2, high=diag_len / 2, size=nlines)\n",
    "\n",
    "rho_mat = np.tile(rho, (nt, 1)).T\n",
    "phi_mat = np.tile(phi, (nt, 1)).T\n",
    "t_mat = np.tile(t, (nlines, 1))\n",
    "posterior = np.zeros((nlines, nt))\n",
    "\n",
    "y_line = ((rho_mat - (t_mat - tmid) * np.cos(phi_mat)) / np.sin(phi_mat)) + pmid\n",
    "y_line = np.rint(y_line).astype(\"int\")\n",
    "\n",
    "# if line falls outside of array in a given bin, replace that with median posterior value of that bin across all positions\n",
    "t_out = np.where((y_line < 0) | (y_line > npos - 1))\n",
    "t_in = np.where((y_line >= 0) & (y_line <= npos - 1))\n",
    "posterior[t_out] = np.median(arr[:, t_out[1]], axis=0)\n",
    "posterior[t_in] = arr[y_line[t_in], t_in[1]]\n",
    "\n",
    "# old_settings = np.seterr(all=\"ignore\")\n",
    "posterior_mean = np.nanmean(posterior, axis=1)\n",
    "\n",
    "best_line = np.argmax(posterior_mean)\n",
    "score = posterior_mean[best_line]\n",
    "best_phi, best_rho = phi[best_line], rho[best_line]\n",
    "time_mid, pos_mid = nt * dt / 2, npos * dx / 2\n",
    "\n",
    "velocity = dx / (dt * np.tan(best_phi))\n",
    "intercept = (\n",
    "    (dx * time_mid) / (dt * np.tan(best_phi))\n",
    "    + (best_rho / np.sin(best_phi)) * dx\n",
    "    + pos_mid\n",
    ")\n",
    "# np.seterr(**old_settings)\n",
    "\n",
    "# return score, -velocity, intercept\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce1618081139d19eb1ee8d40815d94a2de4f62e1efb20d9406ddb60628c36ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('data_analysis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
