{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "from tqdm.notebook import tqdm\n",
    "from neuropy.core import Epoch\n",
    "from neuropy.utils.mathutil import min_max_scaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example radon transform figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subjects\n",
    "from neuropy import plotting\n",
    "from neuropy.analyses import Pf1D\n",
    "from neuropy.analyses import Decode1d\n",
    "from neuropy.analyses.decoders import radon_transform\n",
    "from hfuncs import radon_transform_gpu\n",
    "from time import time\n",
    "\n",
    "s = time()\n",
    "for i in range(100):\n",
    "    radon_transform(np.ones((50, 10)))\n",
    "e = time()\n",
    "print(e - s)\n",
    "\n",
    "s = time()\n",
    "for i in range(5000):\n",
    "    radon_transform_gpu(np.ones((50, 10)))\n",
    "e = time()\n",
    "print(e - s)\n",
    "\n",
    "\n",
    "# sess = subjects.nsd.ratUday2[0]\n",
    "\n",
    "# maze = sess.paradigm[\"maze\"].flatten()\n",
    "# post = sess.paradigm[\"post\"].flatten()\n",
    "# neurons = sess.neurons.get_neuron_type(neuron_type=\"pyr\")\n",
    "# pos = sess.maze\n",
    "# # pos.t_start = pos.t_start - 0.5\n",
    "# run = sess.run\n",
    "# pf = Pf1D(\n",
    "#     neurons=neurons,\n",
    "#     position=pos,\n",
    "#     speed_thresh=4,\n",
    "#     sigma=4,\n",
    "#     grid_bin=2,\n",
    "#     epochs=run,\n",
    "#     frate_thresh=1,\n",
    "# )\n",
    "# # np.random.default_rng().shuffle(pf.tuning_curves)\n",
    "# pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "# epochs = sess.pbe.time_slice(maze[0], maze[0]+500)\n",
    "# decode = Decode1d(\n",
    "#     neurons=pf_neurons, ratemap=pf, epochs=epochs, bin_size=0.02\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from numpy.random import default_rng\n",
    "from neuropy.analyses.decoders import radon_transform\n",
    "from hfuncs import radon_transform_gpu\n",
    "from neuropy import plotting\n",
    "from scipy import stats\n",
    "from neuropy.utils.mathutil import min_max_scaler\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "n_posteriors = len(decode.posterior)\n",
    "posterior_ind = default_rng().integers(0, n_posteriors, n_posteriors)\n",
    "# posterior_ind = [382, 42, 131, 162, 287, 284, 127, 331, 294, 205]\n",
    "# posterior_ind =[189, 139, 180, 178, 188, 103, 158,  15, 123, 156]\n",
    "# posterior_ind= [ 7, 126, 114, 116, 115]\n",
    "arrs = [decode.posterior[i] for i in posterior_ind]\n",
    "len_arr = np.cumsum([_.shape[1] for _ in arrs])[:-1]\n",
    "zsc_tuning = stats.zscore(pf.tuning_curves, axis=1)\n",
    "sort_ind = np.argsort(np.argmax(zsc_tuning, axis=1))\n",
    "post_gpu = cp.asarray(np.hstack(arrs))\n",
    "\n",
    "s = time.time()\n",
    "arrs_gpu = cp.hsplit(post_gpu, len_arr)\n",
    "for i, arr in enumerate(arrs_gpu):\n",
    "\n",
    "    score, velocity, intercept = radon_transform_gpu(arr, dt=0.02, dx=2, neighbours=4)\n",
    "\n",
    "e = time.time()\n",
    "print(e - s)\n",
    "\n",
    "# s = time.time()\n",
    "# for i, arr in enumerate(arrs):\n",
    "#     t_start = epochs[posterior_ind[i]].flatten()[0]\n",
    "#     score, velocity, intercept = radon_transform(arr, dt=0.02, dx=2, neighbours=4)\n",
    "# e = time.time()\n",
    "# print(e-s)\n",
    "\n",
    "s = time.time()\n",
    "results = Parallel(n_jobs=5)(\n",
    "    delayed(radon_transform)(\n",
    "        epoch,\n",
    "        dt=0.02,\n",
    "        dx=2,\n",
    "        neighbours=4,\n",
    "    )\n",
    "    for epoch in arrs\n",
    ")\n",
    "score, velocity, intercept = np.asarray(results).T\n",
    "e = time.time()\n",
    "print(e - s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from numpy.random import default_rng\n",
    "from neuropy.analyses.decoders import radon_transform_gpu,radon_transform\n",
    "from neuropy import plotting\n",
    "from scipy import stats\n",
    "from neuropy.utils.mathutil import min_max_scaler\n",
    "import time\n",
    "\n",
    "n_posteriors = len(decode.posterior)\n",
    "posterior_ind = default_rng().integers(0,n_posteriors,5)\n",
    "# posterior_ind = [382, 42, 131, 162, 287, 284, 127, 331, 294, 205]\n",
    "# posterior_ind =[189, 139, 180, 178, 188, 103, 158,  15, 123, 156]\n",
    "# posterior_ind= [ 7, 126, 114, 116, 115]\n",
    "arrs = [decode.posterior[i] for i in posterior_ind]\n",
    "\n",
    "_, axs = plt.subplots(2, 5,sharey='row',sharex='col')\n",
    "# axs = axs.reshape(-1)\n",
    "zsc_tuning = stats.zscore(pf.tuning_curves,axis=1)\n",
    "sort_ind = np.argsort(np.argmax(zsc_tuning,axis=1))\n",
    "\n",
    "s = time.time()\n",
    "for i, arr in enumerate(arrs):\n",
    "    # arr = min_max_scaler(arr,axis=0)\n",
    "    t_start = epochs[posterior_ind[i]].flatten()[0]\n",
    "\n",
    "    score, velocity, intercept = radon_transform_gpu(arr, dt=0.02, dx=2, neighbours=4)\n",
    "    # arr = np.apply_along_axis(np.convolve, axis=0, arr=arr, v=np.ones(2 * 4 + 1))\n",
    "    # t = np.arange(arr.shape[1]) * 0.02+t_start\n",
    "    # pos = np.arange(arr.shape[0]) * 2\n",
    "\n",
    "    # axs[0,i].pcolormesh(t, pos,arr, cmap=\"hot\")\n",
    "    # axs[0,i].plot(t, velocity * (t-t_start) + intercept, color=\"w\")\n",
    "    # axs[0,i].set_ylim([pos.min(), pos.max()])\n",
    "    # axs[0,i].set_title(score.round(2))\n",
    "\n",
    "    # plotting.plot_raster(pf_neurons[sort_ind].time_slice(t_start=t[0],t_stop=t[-1]),ax=axs[1,i],color='k')\n",
    "e = time.time()\n",
    "print(e-s)\n",
    "\n",
    "s = time.time()\n",
    "for i, arr in enumerate(arrs):\n",
    "    # arr = min_max_scaler(arr,axis=0)\n",
    "    t_start = epochs[posterior_ind[i]].flatten()[0]\n",
    "\n",
    "    score, velocity, intercept = radon_transform(arr, dt=0.02, dx=2, neighbours=4)\n",
    "    # arr = np.apply_along_axis(np.convolve, axis=0, arr=arr, v=np.ones(2 * 4 + 1))\n",
    "    # t = np.arange(arr.shape[1]) * 0.02+t_start\n",
    "    # pos = np.arange(arr.shape[0]) * 2\n",
    "\n",
    "    # axs[0,i].pcolormesh(t, pos,arr, cmap=\"hot\")\n",
    "    # axs[0,i].plot(t, velocity * (t-t_start) + intercept, color=\"w\")\n",
    "    # axs[0,i].set_ylim([pos.min(), pos.max()])\n",
    "    # axs[0,i].set_title(score.round(2))\n",
    "\n",
    "    # plotting.plot_raster(pf_neurons[sort_ind].time_slice(t_start=t[0],t_stop=t[-1]),ax=axs[1,i],color='k')\n",
    "e = time.time()\n",
    "print(e-s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize decoding in one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.nsd.ratUday2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub, sess in enumerate(sessions):\n",
    "    maze = sess.paradigm[\"maze\"].flatten()\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    neurons = sess.neurons.get_neuron_type(neuron_type=\"pyr\")\n",
    "    pos = sess.maze\n",
    "    # pos.t_start = pos.t_start - 0.5\n",
    "    forward = sess.run[\"backward\"]\n",
    "\n",
    "    pf = Pf1D(\n",
    "        neurons=neurons,\n",
    "        position=pos,\n",
    "        speed_thresh=5,\n",
    "        sigma=4,\n",
    "        grid_bin=2,\n",
    "        epochs=forward,\n",
    "        frate_thresh=0.1,\n",
    "    )\n",
    "    pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "    epochs = sess.pbe.time_slice(post[0], post[0] + 2 * 3600)\n",
    "    decode = Decode1d(\n",
    "        neurons=pf_neurons,\n",
    "        ratemap=pf,\n",
    "        epochs=epochs,\n",
    "        bin_size=0.02,\n",
    "        score_method=\"wcorr\",\n",
    "    )\n",
    "    decode.calculate_shuffle_score(n_iter=1000, method=\"neuron_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "bins = np.arange(-1,1,0.1)\n",
    "hist_percentile = np.histogram(decode.score,bins)[0]\n",
    "ax.violinplot(decode.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode.plot_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfuncs import plot_in_bokeh\n",
    "import bokeh.plotting as bplot\n",
    "\n",
    "measure = decode.percentile_score \n",
    "measure[np.isnan(measure)] = 0\n",
    "# bplot.output_file(subjects.figpath_sd/'test_wake_decoding.html')\n",
    "bplot.output_notebook()\n",
    "p = plot_in_bokeh(\n",
    "    x=epochs.starts / 3600,\n",
    "    y=measure,\n",
    "    img_arr=decode.posterior,\n",
    "    color_by=measure,\n",
    "    palette=\"jet\",\n",
    "    size=10,\n",
    ")\n",
    "# p.line(pos.time,pos.x/350 + 0.2,line_width=2,color='black')\n",
    "bplot.show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay score distribution comparison in POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.nsd.pf_sess + subjects.sd.pf_sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = []\n",
    "dist_replay_df = []\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    neurons = sess.neurons.get_neuron_type(neuron_type=\"pyr\")\n",
    "    pos = sess.maze\n",
    "    # run = sess.run\n",
    "    pf = Pf1D(\n",
    "        neurons=neurons,\n",
    "        position=pos,\n",
    "        speed_thresh=5,\n",
    "        sigma=4,\n",
    "        grid_bin=2,\n",
    "        # epochs=run,\n",
    "        frate_thresh=1,\n",
    "    )\n",
    "    pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "    zts = np.array([0, 1, 2, 4, 5, 7])\n",
    "    starts = zts * 3600 + post[0]\n",
    "\n",
    "    epochs = []\n",
    "    for s, zt in zip(starts, zts):\n",
    "        epochs.append(\n",
    "            sess.pbe.time_slice(s, s + 3600).set_labels(f\"{zt+1}\").to_dataframe()\n",
    "        )\n",
    "\n",
    "    epochs = Epoch(pd.concat(epochs, ignore_index=True))\n",
    "\n",
    "    decode = Decode1d(\n",
    "        neurons=pf_neurons,\n",
    "        ratemap=pf,\n",
    "        epochs=epochs,\n",
    "        bin_size=0.02,\n",
    "        decode_margin=15,\n",
    "        nlines=5000,\n",
    "    )\n",
    "    jump_distance = [np.abs(np.diff(_)).mean() for _ in decode.decoded_position]\n",
    "    weighted_corr = decode.weighted_correlation\n",
    "\n",
    "    norm_pos = min_max_scaler(decode.ratemap.xbin_centers)\n",
    "    decoded_position_mean = np.nanmean(np.hstack(decode.posterior), axis=1)\n",
    "    pos_bins = np.linspace(0, 1, 50)\n",
    "    mean_pos = np.interp(pos_bins, norm_pos, decoded_position_mean)\n",
    "\n",
    "    df_dist = pd.DataFrame(\n",
    "        dict(\n",
    "            bins=pos_bins,\n",
    "            mean_pos=mean_pos,\n",
    "            name=sess.animal.name,\n",
    "            grp=sess.tag,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        dict(\n",
    "            score=decode.score,\n",
    "            velocity=decode.velocity,\n",
    "            jump_distance=jump_distance,\n",
    "            weighted_corr=weighted_corr,\n",
    "            epoch=epochs.labels,\n",
    "            name=sess.animal.name,\n",
    "            grp=sess.tag,\n",
    "        )\n",
    "    )\n",
    "    score_df.append(df)\n",
    "    dist_replay_df.append(df_dist)\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n",
    "dist_replay_df = pd.concat(dist_replay_df, ignore_index=True)\n",
    "\n",
    "subjects.GroupData().save(score_df, \"replay_post_score\")\n",
    "subjects.GroupData().save(dist_replay_df, \"replay_pos_distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.concat(score_df, ignore_index=True)\n",
    "dist_replay_df = pd.concat(dist_replay_df, ignore_index=True)\n",
    "\n",
    "subjects.GroupData().save(score_df, \"replay_post_score\")\n",
    "subjects.GroupData().save(dist_replay_df, \"replay_pos_distribution\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "_,ax = plt.subplots()\n",
    "sns.violinplot(\n",
    "    data=score_df,\n",
    "    x=\"epoch\",\n",
    "    y=\"score\",\n",
    "    hue=\"grp\",\n",
    "    split=True,\n",
    "    inner=None,\n",
    "    scale=\"width\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scratch code for pooled randon transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = [_.shape[1] for _ in decode.posterior[:60]]\n",
    "post = np.hstack(decode.posterior[:60])\n",
    "arr = post\n",
    "nlines = 10000\n",
    "dt = 1\n",
    "dx = 1\n",
    "neighbours = 1\n",
    "t = np.concatenate([np.arange(0, _) for _ in nbins])\n",
    "max_t = max(nbins)\n",
    "nt = len(t)\n",
    "tmid = (nt + 1) / 2 - 1\n",
    "\n",
    "pos = np.arange(arr.shape[0])\n",
    "npos = len(pos)\n",
    "pmid = (npos + 1) / 2 - 1\n",
    "\n",
    "# using convolution to sum neighbours\n",
    "arr = np.apply_along_axis(\n",
    "    np.convolve, axis=0, arr=arr, v=np.ones(2 * neighbours + 1), mode=\"same\"\n",
    ")\n",
    "\n",
    "# exclude stationary events by choosing phi little below 90 degree\n",
    "# NOTE: angle of line is given by (90-phi), refer Kloosterman 2012\n",
    "phi = np.random.uniform(low=-np.pi / 2, high=np.pi / 2, size=nlines)\n",
    "diag_len = np.sqrt((max_t - 1) ** 2 + (npos - 1) ** 2)\n",
    "rho = np.random.uniform(low=-diag_len / 2, high=diag_len / 2, size=nlines)\n",
    "\n",
    "rho_mat = np.tile(rho, (nt, 1)).T\n",
    "phi_mat = np.tile(phi, (nt, 1)).T\n",
    "t_mat = np.tile(t, (nlines, 1))\n",
    "posterior = np.zeros((nlines, nt))\n",
    "\n",
    "y_line = ((rho_mat - (t_mat - tmid) * np.cos(phi_mat)) / np.sin(phi_mat)) + pmid\n",
    "y_line = np.rint(y_line).astype(\"int\")\n",
    "\n",
    "# if line falls outside of array in a given bin, replace that with median posterior value of that bin across all positions\n",
    "t_out = np.where((y_line < 0) | (y_line > npos - 1))\n",
    "t_in = np.where((y_line >= 0) & (y_line <= npos - 1))\n",
    "posterior[t_out] = np.median(arr[:, t_out[1]], axis=0)\n",
    "posterior[t_in] = arr[y_line[t_in], t_in[1]]\n",
    "\n",
    "# old_settings = np.seterr(all=\"ignore\")\n",
    "posterior_mean = np.nanmean(posterior, axis=1)\n",
    "\n",
    "best_line = np.argmax(posterior_mean)\n",
    "score = posterior_mean[best_line]\n",
    "best_phi, best_rho = phi[best_line], rho[best_line]\n",
    "time_mid, pos_mid = nt * dt / 2, npos * dx / 2\n",
    "\n",
    "velocity = dx / (dt * np.tan(best_phi))\n",
    "intercept = (\n",
    "    (dx * time_mid) / (dt * np.tan(best_phi))\n",
    "    + (best_rho / np.sin(best_phi)) * dx\n",
    "    + pos_mid\n",
    ")\n",
    "# np.seterr(**old_settings)\n",
    "\n",
    "# return score, -velocity, intercept\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce1618081139d19eb1ee8d40815d94a2de4f62e1efb20d9406ddb60628c36ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('data_analysis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
