{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Check recording info"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import subjects\n",
    "\n",
    "sess = subjects.nsd.ratNday2[0]\n",
    "print(sess.recinfo)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set probe configuration\n",
    "Lets create probe configuration for a 128-channel probe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from neuropy.core import Shank, Probe, ProbeGroup\n",
    "from neuropy.plotting import plot_probe\n",
    "\n",
    "shanks = []\n",
    "channel_groups = sess.recinfo.channel_groups\n",
    "for i in range(8):\n",
    "\n",
    "    shank = Shank.auto_generate(\n",
    "        columns=2,\n",
    "        contacts_per_column=8,\n",
    "        xpitch=15,\n",
    "        ypitch=20,\n",
    "        y_shift_per_column=[0, -7.5],\n",
    "        channel_id=np.append(\n",
    "            channel_groups[i][::2][::-1], channel_groups[i][1::2][::-1]\n",
    "        ),\n",
    "    )\n",
    "    shanks.append(shank)\n",
    "    shank.set_disconnected_channels(sess.recinfo.skipped_channels)\n",
    "\n",
    "probe1 = Probe(shanks)\n",
    "\n",
    "probe2 = Probe(shanks)\n",
    "probe2.move((probe1.x_max+500,0))\n",
    "\n",
    "prbgrp = ProbeGroup()\n",
    "prbgrp.add_probe(probe1)\n",
    "prbgrp.add_probe(probe2)\n",
    "\n",
    "# prbgrp.filename = sess.filePrefix.with_suffix(\".probegroup.npy\")\n",
    "# prbgrp.save()\n",
    "plot_probe(prbgrp)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create epochs for your experimental paradigm\n",
    "A typical experiment involves multiple epochs such pre sleep, running on track and then another sleep epoch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "epochs = pd.DataFrame(\n",
    "    {\n",
    "        \"start\": [0, 10000, 20000],\n",
    "        \"stop\": [9000, 13600, 30000],\n",
    "        \"label\": [\"pre\", \"maze\", \"post\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "a = Epoch(epochs=epochs)\n",
    "a.filename = sess.filePrefix.with_suffix(\".paradigm.npy\")\n",
    "a.save()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detect epochs\n",
    "Here we will various types of epochs which typical for hippocampal recordings."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Artifacts epochs\n",
    "A typical session will have some artifacts that may negatively influence many analyses. Using a simple zscore measure, we can identify epochs where signal is above some threshold."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "signal = sess.eegfile.get_signal([1])\n",
    "artifact_epochs = analyses.detect_artifact_epochs(signal, thresh=7)\n",
    "artifact_epochs.filename = sess.filePrefix.with_suffix(\".artifact.npy\")\n",
    "artifact_epochs.save()\n",
    "plotting.plot_artifact_epochs(artifact_epochs, signal)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ripple epochs\n",
    "To detect ripples one also needs probegroup."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from neuropy.analyses import oscillations\n",
    "signal = sess.eegfile.get_signal()\n",
    "ripple_epochs =oscillations.detect_ripple_epochs(signal, sess.probegroup)\n",
    "ripple_epochs.filename = sess.filePrefix.with_suffix('.ripple.npy')\n",
    "ripple_epochs.save()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "signal = sess.eegfile.get_signal(channel_id=[1, 2, 3, 4], t_start=1, t_stop=1.2)\n",
    "plotting.plot_signal_traces(signal)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neurons\n",
    "- import spiketrains from Phy\n",
    "- estimate neuron types such pyramidal, interneuron etc. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing spiketrains from Phy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from neuropy.io import PhyIO\n",
    "from neuropy.core import Neurons\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "cluster_path = Path(\n",
    "    \"/data/Clustering/sessions/RatN/Day1/spykcirc/clus_combined\"\n",
    ")\n",
    "chan_grps = sess.recinfo.channel_groups\n",
    "sub_dirs = sorted([x for x in cluster_path.iterdir() if x.is_dir()])\n",
    "\n",
    "spk, peak_chans,waveforms,shank_id = [], [],[],[]\n",
    "for f_ind, folder in enumerate(sub_dirs):\n",
    "    print(folder)\n",
    "    phy_data = PhyIO(folder)\n",
    "    spk.extend(phy_data.spiketrains)\n",
    "    peak_chans.extend(chan_grps[f_ind][phy_data.peak_channels])\n",
    "    waveforms.extend(phy_data.peak_waveforms)\n",
    "    shank_id.extend([f_ind]*len(phy_data.spiketrains))\n",
    "\n",
    "\n",
    "\n",
    "peak_chans = np.array(peak_chans)\n",
    "\n",
    "neurons = Neurons(\n",
    "    np.array(spk, dtype=object),\n",
    "    t_stop=sess.eegfile.duration,\n",
    "    sampling_rate=phy_data.sampling_rate,\n",
    "    peak_channels=peak_chans,\n",
    "    waveforms=np.array(waveforms,dtype='object'),\n",
    "    shank_ids=np.array(shank_id)\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Estimate neuron type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib widget\n",
    "from neuropy.utils import neurons_util\n",
    "neuron_type = neurons_util.estimate_neuron_type(sess.neurons)\n",
    "sess.neurons.neuron_type = neuron_type"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "neurons.filename = sess.filePrefix.with_suffix('.neurons')\n",
    "neurons.save()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy.plotting import plot_raster\n",
    "\n",
    "plot_raster(neurons,color='jet',add_vert_jitter=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BinnedSpiketrain and Mua objects using Neurons"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mua =sess.neurons.get_mua()\n",
    "mua.filename = sess.filePrefix.with_suffix(\".mua.npy\")\n",
    "mua.save()   \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib widget\n",
    "from neuropy import plotting\n",
    "smth_mua = sess.mua.get_smoothed(sigma=0.02)\n",
    "plotting.plot_mua(smth_mua)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from neuropy.analyses import detect_pbe_epochs\n",
    "\n",
    "pbe = detect_pbe_epochs(smth_mua)\n",
    "pbe.filename = sess.filePrefix.with_suffix('.pbe')\n",
    "pbe.save()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assign position data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from neuropy.io import OptitrackIO\n",
    "from neuropy.core import Position\n",
    "from pathlib import Path\n",
    "\n",
    "opti_folder = sess.filePrefix.parent / 'position'\n",
    "opti_data = OptitrackIO(dirname=opti_folder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#---- startimes of concatenated .dat files\n",
    "tracking_sRate = opti_data.sampling_rate\n",
    "rec_datetime = pd.read_csv(sess.filePrefix.with_suffix('.datetime.csv'))\n",
    "data_time = []\n",
    "for i, file_time in enumerate(rec_datetime[\"StartTime\"]):\n",
    "    tbegin = datetime.strptime(file_time, \"%Y-%m-%d_%H-%M-%S\")\n",
    "    nframes = rec_datetime[\"nFrames\"][i]\n",
    "    duration = pd.Timedelta(nframes / sess.recinfo.dat_sampling_rate, unit=\"sec\")\n",
    "    tend = tbegin + duration\n",
    "    trange = pd.date_range(\n",
    "        start=tbegin,\n",
    "        end=tend,\n",
    "        periods=int(duration.total_seconds() * tracking_sRate),\n",
    "    )\n",
    "    data_time.extend(trange)\n",
    "data_time = pd.to_datetime(data_time)\n",
    "\n",
    "# ------- deleting intervals that were deleted from .dat file after concatenating\n",
    "ndeletedintervals = rec_datetime.count()[\"deletedStart (minutes)\"]\n",
    "for i in range(ndeletedintervals):\n",
    "    tnoisy_begin = data_time[0] + pd.Timedelta(\n",
    "        rec_datetime[\"deletedStart (minutes)\"][i], unit=\"m\"\n",
    "    )\n",
    "    tnoisy_end = data_time[0] + pd.Timedelta(\n",
    "        rec_datetime[\"deletedEnd (minutes)\"][i], unit=\"m\"\n",
    "    )\n",
    "\n",
    "    del_index = np.where((data_time > tnoisy_begin) & (data_time < tnoisy_end))[\n",
    "        0\n",
    "    ]\n",
    "\n",
    "    data_time = np.delete(data_time, del_index)\n",
    "\n",
    "x,y,z = opti_data.get_position_at_datetimes(data_time)\n",
    "traces = np.vstack((z,x,y))\n",
    "\n",
    "position = Position(traces=traces,t_start=0,sampling_rate=opti_data.sampling_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "position.filename = sess.filePrefix.with_suffix('.position.npy')\n",
    "position.save()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(opti_data.datetime_array,opti_data.z)\n",
    "plt.plot(position.x,position.y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib widget\n",
    "from neuropy.utils import signal_process\n",
    "\n",
    "signal = sess.eegfile.get_signal([40])\n",
    "\n",
    "spec = signal_process.spectrogramBands(signal.traces[0])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(spec.time+0.25,spec.theta/500)\n",
    "plt.plot(sess.position.time,sess.position.y)\n",
    "plt.plot(sess.position.time[1:],np.diff(sess.position.y)*100)\n",
    "plt.xlim([12500,12600])\n",
    "plt.ylim([-400,400])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linearize position"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from neuropy.utils import position_util\n",
    "\n",
    "maze = sess.paradigm['maze']\n",
    "maze_pos = sess.position.time_slice(maze[0],maze[1])\n",
    "linear_pos = position_util.linearize_position(maze_pos)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "linear_pos.y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib widget\n",
    "plt.plot(maze_pos.time,maze_pos.x)\n",
    "plt.plot(linear_pos.time,linear_pos.x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(5)\n",
    "np.vstack((a,a,a)).shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from neuropy.core import animal\n",
    "\n",
    "d = {'name':'hello','tag':'ser'}\n",
    "\n",
    "an = animal.Animal(d) \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import time\n",
    "\n",
    "time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(4917008))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "4917000/30000"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b10c821bc4bd3f433a613d47515e6babc6c2152896bd1e143404cc9d6ede4ad"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('data_analysis': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}