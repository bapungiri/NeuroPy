{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "class A:\n",
    "    # __slots__ = 'path','ripple_psd','ripple_rate'\n",
    "    def __init__(self) -> None:\n",
    "        self.path = Path(\"/home/bapung/Dropbox (University of Michigan)/ProcessedData\")\n",
    "        for f in self.path.iterdir():\n",
    "            setattr(self,f.name,self.load(f.stem))\n",
    "\n",
    "    def load(self, fp):\n",
    "        return np.load(self.path / f\"{fp}.npy\", allow_pickle=True).item()\n",
    "\n",
    "    # def __getattr__(self,name: str):\n",
    "    #     return self.load(name)['data'] \n",
    "\n",
    "\n",
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subjects\n",
    "\n",
    "subjects.GroupData().replay_re_maze_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def go_fast(a): # Function is compiled and runs in machine code\n",
    "    trace = 0.0\n",
    "    for i in range(a.shape[0]):\n",
    "        trace += np.tanh(a[i, i])\n",
    "    return a + trace\n",
    "\n",
    "# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n",
    "start = time.time()\n",
    "go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))\n",
    "\n",
    "# NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE\n",
    "start = time.time()\n",
    "go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "n=300\n",
    "### Numpy and CPU\n",
    "s = time.time()\n",
    "X_cpu = np.ones((n,n,n))\n",
    "e = time.time()\n",
    "print(e - s) ### CuPy and GPU\n",
    "s = time.time()\n",
    "X_gpu = cp.ones((n,n,n))\n",
    "e = time.time()\n",
    "print(e - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import subjects\n",
    "\n",
    "sess = subjects.sd.ratNday1[0]\n",
    "chan_order = np.concatenate(sess.recinfo.channel_groups)\n",
    "chan_order = np.concatenate([chan_order ,chan_order[:64]+128]).astype('int')\n",
    "\n",
    "basefolder = Path(\"/data2/Clustering/RatU/RatUDay1SD/\")\n",
    "file = basefolder / \"RatU_Day1SD_2021-07-22_07-55-46.eeg\"\n",
    "n_channels = 256\n",
    "# data = np.memmap(file, dtype=\"int16\", mode=\"r\").reshape(-1, n_channels)[:,chan_order]\n",
    "# data.tofile(basefolder/'RatU_192chan1.eeg',format='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_filename=basefolder/'RatU_192chan.eeg'\n",
    "write_data = np.memmap(\n",
    "            write_filename, dtype='int16', mode=\"w+\", shape=(data_new.size)\n",
    "        )\n",
    "write_data[: data_new.size] = data_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from neuropy.core import Epoch\n",
    "import subjects\n",
    "\n",
    "sess = subjects.nsd.ratKday2[0]\n",
    "\n",
    "file = Path('/data/Clustering/sessions/RatK/Day2/RatK_Day2_2019-08-08_04-00-00.dead')\n",
    "ep = []\n",
    "with open(file,mode='r') as f:\n",
    "    for line in f:\n",
    "        ep.append(np.asarray(line.strip('\\n').split(' ')).astype('float'))\n",
    "ep = np.asarray(ep)/1000\n",
    "\n",
    "epochs = Epoch.from_array(ep[:,0],ep[:,1])\n",
    "epochs.save(sess.filePrefix.with_suffix('.artifact'))\n",
    "\n",
    "    \n",
    "# test = file.read_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy import plotting\n",
    "\n",
    "plotting.plot_raster(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg, AutoRegResults\n",
    "import subjects\n",
    "from hfuncs import whiten_signal\n",
    "\n",
    "sess = subjects.sd.ratNday1[0]\n",
    "# period = sess.paradigm['maze'].flatten()\n",
    "period = sess.ripple[6000].flatten()\n",
    "signal = sess.eegfile.get_signal(32,period[0],period[0]+2)\n",
    "wht = whiten_signal(signal)\n",
    "# mod = AutoReg(signal,2,old_names=False)\n",
    "# res = mod.fit()\n",
    "# new_sig = res.predict(0,len(signal)+1)\n",
    "# residual = signal-new_sig[2:]\n",
    "# result = AutoRegResults(mod,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the PdfPages object to which we will save the pages:\n",
    "# The with statement makes sure that the PdfPages object is closed properly at\n",
    "# the end of the block, even if an Exception occurs.\n",
    "with PdfPages('multipage_pdf.pdf') as pdf:\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.plot(range(7), [3, 1, 4, 1, 5, 9, 2], 'r-o')\n",
    "    plt.title('Page One')\n",
    "    pdf.savefig()  # saves the current figure into a pdf page\n",
    "    plt.close()\n",
    "\n",
    "    # if LaTeX is not installed or error caught, change to `False`\n",
    "    # plt.rcParams['text.usetex'] = False\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    x = np.arange(0, 5, 0.1)\n",
    "    plt.plot(x, np.sin(x), 'b-')\n",
    "    plt.title('Page Two')\n",
    "    pdf.attach_note(\"plot of sin(x)\")  # attach metadata (as pdf note) to page\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # plt.rcParams['text.usetex'] = False\n",
    "    fig = plt.figure(figsize=(4, 5))\n",
    "    plt.plot(x, x ** 2, 'ko')\n",
    "    plt.title('Page Three')\n",
    "    pdf.savefig(fig)  # or you can pass a Figure object to pdf.savefig\n",
    "    plt.close()\n",
    "\n",
    "    # We can also set the file's metadata via the PdfPages object:\n",
    "    d = pdf.infodict()\n",
    "    d['Title'] = 'Multipage PDF Example'\n",
    "    d['Author'] = 'Jouni K. Sepp\\xe4nen'\n",
    "    d['Subject'] = 'How to create a multipage pdf file and set its metadata'\n",
    "    d['Keywords'] = 'PdfPages multipage keywords author title subject'\n",
    "    d['CreationDate'] = datetime.datetime(2009, 11, 13)\n",
    "    d['ModDate'] = datetime.datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sg\n",
    "f,psd1 = sg.welch(signal.traces[0],fs=1250,nperseg=1250,noverlap=625)\n",
    "f,psd2 = sg.welch(wht.traces[0],fs=1250,nperseg=1250,noverlap=625)\n",
    "# f,psd3 = sg.welch(res.resid,fs=1250,nperseg=1250,noverlap=625)\n",
    "plt.plot(f,psd1)\n",
    "plt.plot(f,psd2)\n",
    "# plt.plot(f,psd3)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "# plt.plot(new_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neuropy.utils.signal_process import WaveletSg\n",
    "\n",
    "wvlt = WaveletSg(wht,freqs=np.arange(100,250,2),ncycles=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, axs = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "axs[0].plot(np.linspace(0, 2, len(signal.traces[0])), signal.traces[0], \"k\")\n",
    "axs[1].imshow(\n",
    "    wvlt.traces,\n",
    "    aspect=\"auto\",\n",
    "    extent=[0, 2, 100, 250],\n",
    "    origin=\"lower\",\n",
    "    interpolation=\"none\",\n",
    "    # vmax=130,\n",
    "    cmap='jet',\n",
    ")\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.plot(signal.traces[0])\n",
    "plt.plot(wht.traces[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subjects\n",
    "\n",
    "sess = subjects.nsd.ratKday2[0]\n",
    "maze = sess.paradigm['maze'].flatten()\n",
    "dest_file = sess.filePrefix.with_suffix('.maze.eeg')\n",
    "sess.eegfile.write_time_slice(dest_file,int(maze[0]),int(maze[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_name = \"RatU_Day4SD_2021-07-29_08-23-06.eeg_sample.eeg\"\n",
    "n_channels = 192 # number of recorded channels in the file\n",
    "sampling_rate = 1250\n",
    "# reading data from binary file and reshaping to n_channels x time format\n",
    "data = np.memmap(file_name,dtype='int16',mode='r').reshape(-1,n_channels).T\n",
    "\n",
    "#let's plot data from first channel\n",
    "plt.plot(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "from neuropy.plotting import Fig\n",
    "\n",
    "def example_plot(ax, fontsize=12, hide_labels=False):\n",
    "    pc = ax.pcolormesh(np.random.randn(30, 30), vmin=-2.5, vmax=2.5)\n",
    "    if not hide_labels:\n",
    "        ax.set_xlabel('x-label', fontsize=fontsize)\n",
    "        ax.set_ylabel('y-label', fontsize=fontsize)\n",
    "        ax.set_title('Title', fontsize=fontsize)\n",
    "    return pc\n",
    "\n",
    "figure = Fig()\n",
    "fig,gs = figure.draw(grid=(4,4))\n",
    "\n",
    "ax = figure.add_subplot(gs[:,2:])\n",
    "ax.plot(np.arange(10),np.arange(10))\n",
    "\n",
    "subfig = fig.add_subfigure(gs[:,:2])\n",
    "axsLeft = subfig.subplots(1, 2, sharey=True)\n",
    "subfig.set_facecolor('0.75')\n",
    "for ax in axsLeft:\n",
    "    pc = example_plot(ax)\n",
    "subfig.suptitle('Left plots', fontsize='x-large')\n",
    "subfig.colorbar(pc, shrink=0.6, ax=axsLeft, location='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import HoverTool, CustomJS, ColumnDataSource\n",
    "\n",
    "N = 20\n",
    "x = np.random.random(size=N)\n",
    "y = np.random.random(size=N)\n",
    "\n",
    "p = figure(tools=[\"hover\"], toolbar_location=None)\n",
    "p.scatter(x, y, size=10)\n",
    "\n",
    "img_x = np.linspace(0, 10, N)\n",
    "img_y = np.linspace(0, 10, N)\n",
    "\n",
    "images = []\n",
    "for a, b in zip(x, y):\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    d = np.sin(a * xx) * np.cos(b * yy)\n",
    "    images.append(d)\n",
    "\n",
    "imgs_source = ColumnDataSource(data=dict(images=images))\n",
    "img_source = ColumnDataSource(data=dict(image=[]))\n",
    "\n",
    "img = figure(x_range=(0, 10), y_range=(0, 10), tools=[], toolbar_location=None)\n",
    "img.image(image=\"image\", x=0, y=0, dw=10, dh=10, source=img_source, palette=\"Greys7\")\n",
    "\n",
    "hover = p.select_one(HoverTool)\n",
    "hover.callback = CustomJS(\n",
    "    args=dict(imgs_source=imgs_source, img_source=img_source),\n",
    "    code=\"\"\"\n",
    "var indices = cb_data.index['1d'].indices;\n",
    "if (indices.length > 0) {\n",
    "    var img = imgs_source.data.images[indices[0]];\n",
    "    img_source.data = {image: [img]};\n",
    "} else {\n",
    "    img_source.data = {image: []};\n",
    "}\n",
    "\"\"\",\n",
    ")\n",
    "hover.tooltips = None\n",
    "\n",
    "output_file(\"linked_hover.html\")\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from math import cos, pi, sin\n",
    "\n",
    "from bokeh.colors.named import firebrick, lightgray, orchid, seagreen, skyblue, tomato\n",
    "from bokeh.document import Document\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.models import (\n",
    "    AnnularWedge,\n",
    "    ColumnDataSource,\n",
    "    ImageURL,\n",
    "    Plot,\n",
    "    Range1d,\n",
    "    Text,\n",
    "    Wedge,\n",
    ")\n",
    "from bokeh.resources import INLINE\n",
    "from bokeh.sampledata.browsers import browsers_nov_2013, icons\n",
    "from bokeh.util.browser import view\n",
    "\n",
    "df = browsers_nov_2013\n",
    "\n",
    "xdr = Range1d(start=-2, end=2)\n",
    "ydr = Range1d(start=-2, end=2)\n",
    "\n",
    "plot = Plot(x_range=xdr, y_range=ydr, width=800, height=800)\n",
    "plot.title.text = \"Web browser market share (November 2013)\"\n",
    "plot.toolbar_location = None\n",
    "\n",
    "colors = {\n",
    "    \"Chrome\": seagreen,\n",
    "    \"Firefox\": tomato,\n",
    "    \"Safari\": orchid,\n",
    "    \"Opera\": firebrick,\n",
    "    \"IE\": skyblue,\n",
    "    \"Other\": lightgray,\n",
    "}\n",
    "\n",
    "aggregated = df.groupby(\"Browser\").agg(sum)\n",
    "selected = aggregated[aggregated.Share >= 1].copy()\n",
    "selected.loc[\"Other\"] = aggregated[aggregated.Share < 1].sum()\n",
    "browsers = selected.index.tolist()\n",
    "\n",
    "radians = lambda x: 2 * pi * (x / 100)\n",
    "angles = selected.Share.map(radians).cumsum()\n",
    "\n",
    "end_angles = angles.tolist()\n",
    "start_angles = [0] + end_angles[:-1]\n",
    "\n",
    "browsers_source = ColumnDataSource(\n",
    "    dict(\n",
    "        start=start_angles,\n",
    "        end=end_angles,\n",
    "        colors=[colors[browser] for browser in browsers],\n",
    "    )\n",
    ")\n",
    "\n",
    "glyph = Wedge(\n",
    "    x=0,\n",
    "    y=0,\n",
    "    radius=1,\n",
    "    line_color=\"white\",\n",
    "    line_width=2,\n",
    "    start_angle=\"start\",\n",
    "    end_angle=\"end\",\n",
    "    fill_color=\"colors\",\n",
    ")\n",
    "plot.add_glyph(browsers_source, glyph)\n",
    "\n",
    "\n",
    "def polar_to_cartesian(r, start_angles, end_angles):\n",
    "    cartesian = lambda r, alpha: (r * cos(alpha), r * sin(alpha))\n",
    "    points = []\n",
    "\n",
    "    for start, end in zip(start_angles, end_angles):\n",
    "        points.append(cartesian(r, (end + start) / 2))\n",
    "\n",
    "    return zip(*points)\n",
    "\n",
    "\n",
    "first = True\n",
    "\n",
    "for browser, start_angle, end_angle in zip(browsers, start_angles, end_angles):\n",
    "    versions = df[(df.Browser == browser) & (df.Share >= 0.5)]\n",
    "    angles = versions.Share.map(radians).cumsum() + start_angle\n",
    "    end = angles.tolist() + [end_angle]\n",
    "    start = [start_angle] + end[:-1]\n",
    "    base_color = colors[browser]\n",
    "    fill = [base_color.lighten(i * 0.05).to_hex() for i in range(len(versions) + 1)]\n",
    "    # extra empty string accounts for all versions with share < 0.5 together\n",
    "    text = [\n",
    "        number if share >= 1 else \"\"\n",
    "        for number, share in zip(versions.VersionNumber, versions.Share)\n",
    "    ] + [\"\"]\n",
    "    x, y = polar_to_cartesian(1.25, start, end)\n",
    "\n",
    "    source = ColumnDataSource(dict(start=start, end=end, fill=fill))\n",
    "    glyph = AnnularWedge(\n",
    "        x=0,\n",
    "        y=0,\n",
    "        inner_radius=1,\n",
    "        outer_radius=1.5,\n",
    "        start_angle=\"start\",\n",
    "        end_angle=\"end\",\n",
    "        line_color=\"white\",\n",
    "        line_width=2,\n",
    "        fill_color=\"fill\",\n",
    "    )\n",
    "    plot.add_glyph(source, glyph)\n",
    "\n",
    "    text_angle = [(start[i] + end[i]) / 2 for i in range(len(start))]\n",
    "    text_angle = [\n",
    "        angle + pi if pi / 2 < angle < 3 * pi / 2 else angle for angle in text_angle\n",
    "    ]\n",
    "\n",
    "    text_source = ColumnDataSource(dict(text=text, x=x, y=y, angle=text_angle))\n",
    "    glyph = Text(\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        text=\"text\",\n",
    "        angle=\"angle\",\n",
    "        text_align=\"center\",\n",
    "        text_baseline=\"middle\",\n",
    "        text_font_size=\"11px\",\n",
    "    )\n",
    "    plot.add_glyph(text_source, glyph)\n",
    "\n",
    "\n",
    "def to_base64(png):\n",
    "    return \"data:image/png;base64,\" + base64.b64encode(png).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "urls = [to_base64(icons.get(browser, b\"\")) for browser in browsers]\n",
    "x, y = polar_to_cartesian(1.7, start_angles, end_angles)\n",
    "\n",
    "icons_source = ColumnDataSource(dict(urls=urls, x=x, y=y))\n",
    "glyph = ImageURL(url=\"urls\", x=\"x\", y=\"y\", anchor=\"center\")\n",
    "plot.add_glyph(icons_source, glyph)\n",
    "\n",
    "text = [\"%.02f%%\" % value for value in selected.Share]\n",
    "x, y = polar_to_cartesian(0.7, start_angles, end_angles)\n",
    "\n",
    "text_source = ColumnDataSource(dict(text=text, x=x, y=y))\n",
    "glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_align=\"center\", text_baseline=\"middle\")\n",
    "plot.add_glyph(text_source, glyph)\n",
    "\n",
    "doc = Document()\n",
    "doc.add_root(plot)\n",
    "doc.validate()\n",
    "\n",
    "filename = \"donut.html\"\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(file_html(doc, INLINE, \"Donut Chart\"))\n",
    "print(\"Wrote %s\" % filename)\n",
    "view(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, TimeFreqViewer\n",
    "from ephyviewer import InMemoryAnalogSignalSource\n",
    "import ephyviewer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# you must first create a main Qt application (for event loop)\n",
    "app = mkQApp()\n",
    "\n",
    "# create fake 16 signals with 100000 at 10kHz\n",
    "sigs = np.random.rand(100000, 16)\n",
    "sample_rate = 1000.0\n",
    "t_start = 0.0\n",
    "\n",
    "# Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# Create a datasource for the viewer\n",
    "# here we use InMemoryAnalogSignalSource but\n",
    "# you can alose use your custum datasource by inheritance\n",
    "source = InMemoryAnalogSignalSource(sigs, sample_rate, t_start)\n",
    "\n",
    "# create a viewer for signal with TraceViewer\n",
    "view1 = TraceViewer(source=source, name=\"trace\")\n",
    "view1.params[\"scale_mode\"] = \"same_for_all\"\n",
    "view1.auto_scale()\n",
    "win.add_view(view1)\n",
    "\n",
    "sigs = np.random.rand(100000, 16)\n",
    "sample_rate = 1200.0\n",
    "t_start = 30.0\n",
    "\n",
    "source2 = InMemoryAnalogSignalSource(sigs, sample_rate, t_start)\n",
    "\n",
    "\n",
    "# create a time freq viewer conencted to the same source\n",
    "view1 = TraceViewer(source=source2, name=\"trace2\")\n",
    "view1.params[\"scale_mode\"] = \"same_for_all\"\n",
    "view1.auto_scale()\n",
    "\n",
    "# add them to mainwindow\n",
    "win.add_view(view1)\n",
    "\n",
    "\n",
    "# show main window and run Qapp\n",
    "win.show()\n",
    "app.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subjects\n",
    "from neuropy.core import Signal\n",
    "from neuropy_viewer import view_multiple_signals\n",
    "from neuropy.utils import signal_process\n",
    "\n",
    "sess = subjects.nsd.ratUday2[0]\n",
    "maze = sess.paradigm[\"maze\"]\n",
    "eeg = sess.eegfile.get_signal(107, maze[0], maze[1])\n",
    "\n",
    "spec = signal_process.SpectrogramBands(eeg, window=1, overlap=0.5)\n",
    "theta_signal = Signal(spec.theta.reshape(1, -1), sampling_rate=2, t_start=eeg.t_start)\n",
    "\n",
    "position = sess.position.time_slice(maze[0], maze[1])\n",
    "pos_signal = Signal(position.traces, position.sampling_rate, position.t_start)\n",
    "view_multiple_signals([eeg, theta_signal, pos_signal])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce1618081139d19eb1ee8d40815d94a2de4f62e1efb20d9406ddb60628c36ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('data_analysis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
