{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel reordering of .dat and .eeg to be consistent with other ratU sessions\n",
    "Original .dat file (located in google_shared_drive/diba lab data/Bapun/RatUDay1SD/Raw_data/RatU_Day1SD_256chan_64badchan_and_not_channel_odrdered.dat) which has 256 channels out of which 64 channels were bad. So new files below have only 192 channels and channels were re-ordered to reflect depthwise channel mapping:\n",
    "- .eeg file channels were re-ordered using python\n",
    "- .dat file channels were re-ordered using process_extractchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import subjects\n",
    "\n",
    "#--- Original channel order of ratU file is similar to ratN, so getting channel order from there -----\n",
    "sess = subjects.sd.ratNday1[0]\n",
    "chan_order = np.concatenate(sess.recinfo.channel_groups)\n",
    "\n",
    "# ---- ratN had only one 8-shank diagbio probe, but ratU had 2 of these, with 64 channels bad in second probe ----\n",
    "chan_order = np.concatenate([chan_order ,chan_order[:64]+128]).astype('int')\n",
    "\n",
    "basefolder = Path(\"/data2/Clustering/RatU/RatUDay1SD/\")\n",
    "file = basefolder / \"RatU_Day1SD_2021-07-22_07-55-46.eeg\"\n",
    "n_channels = 256\n",
    "\n",
    "#---- reordering (uncomment to run again) --------\n",
    "# data = np.memmap(file, dtype=\"int16\", mode=\"r\").reshape(-1, n_channels)[:,chan_order]\n",
    "# data.tofile(basefolder/'RatU_192chan1.eeg',format='int16')\n",
    "\n",
    "#---- chan_order was written to text file for using in process_extractchannels\n",
    "# textfile = open(sess.filePrefix.with_suffix('.channels.txt'), \"w\")\n",
    "# for element in list(chan_order):\n",
    "#     textfile.write(str(element) + \" \")\n",
    "# textfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RatU Day1 SD recording info\n",
    "- No timestamps were deleted after concatenating .dat files from various folders of open-ephys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subjects\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy.utils import position_util\n",
    "\n",
    "sess = subjects.sd.ratUday1[0]\n",
    "print(sess.recinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set probe configuration\n",
    "- RatU_Day1SD has two probes: both 128chan-8shanks diagnostic biochips.\n",
    "- 64 channels in one of the probes (implanted in left hemisphere) had no signal from 4 shanks (probably one of the intan chips was faulty). So only 192 channels were recorded, the channels in .dat file are already order according to depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy.core import Shank,Probe, ProbeGroup\n",
    "from neuropy.plotting import plot_probe\n",
    "\n",
    "shanks = []\n",
    "channel_groups = sess.recinfo.channel_groups\n",
    "badchans = sess.recinfo.skipped_channels\n",
    "\n",
    "#--- diagnostic-biochip 8 shanks -----------\n",
    "for i in range(8):\n",
    "    chans = channel_groups[i]\n",
    "    shank =Shank.auto_generate(\n",
    "        columns=2,\n",
    "        contacts_per_column=8,\n",
    "        xpitch=15,\n",
    "        ypitch=30,\n",
    "        y_shift_per_column=[0,-15],\n",
    "        channel_id=np.append(\n",
    "            channel_groups[i][::2][::-1], channel_groups[i][1::2][::-1]\n",
    "        ),\n",
    "    )\n",
    "    shank.set_disconnected_channels(sess.recinfo.skipped_channels)\n",
    "    shanks.append(shank)\n",
    "\n",
    "probe1 = Probe(shanks)\n",
    "\n",
    "#--- dignostic biochip 4 shanks (4 shanks were bad) ----------- \n",
    "shanks = []\n",
    "for i in range(8,12):\n",
    "\n",
    "    shank = shank.auto_generate(\n",
    "        columns=2,\n",
    "        contacts_per_column=8,\n",
    "        xpitch=15,\n",
    "        ypitch=30,\n",
    "        y_shift_per_column=[0, -15],\n",
    "        channel_id=np.append(\n",
    "            channel_groups[i][::2][::-1], channel_groups[i][1::2][::-1]\n",
    "        ),\n",
    "    )\n",
    "    shank.set_disconnected_channels(sess.recinfo.skipped_channels)\n",
    "    shanks.append(shank)\n",
    "\n",
    "\n",
    "probe2 = Probe(shanks)\n",
    "probe2.move((probe1.x_max+500,0))\n",
    "\n",
    "prbgrp =ProbeGroup()\n",
    "prbgrp.add_probe(probe1)\n",
    "prbgrp.add_probe(probe2)\n",
    "\n",
    "prbgrp.save(sess.filePrefix.with_suffix('.probegroup.npy'))\n",
    "plot_probe(prbgrp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to json format for spyking-circus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils import probe_util\n",
    "\n",
    "file = sess.filePrefix.with_suffix(\".prb\")\n",
    "probe_util.write_spyking_circus(\n",
    "    file, sess.probegroup, rmv_badchans=True, combine_shanks=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create experimental paradigm\n",
    "- pre sleep is a little shorter\n",
    "- animal was lazy on re-maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.paradigm.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "datetime_data = pd.read_csv(sess.filePrefix.with_suffix('.datetime.csv'))\n",
    "durations = datetime_data.nFrames/sess.recinfo.dat_sampling_rate\n",
    "epochs = pd.DataFrame(\n",
    "    {\n",
    "        \"start\": [0,10371,13683,31691,13683,46094],\n",
    "        \"stop\": [10370,13682,31691,46093,46093,49832],\n",
    "        \"label\": [\"pre\", \"maze\", \"sd\",'rs','post','re-maze'],\n",
    "    }\n",
    ")\n",
    "\n",
    "paradigm = Epoch(epochs=epochs)\n",
    "paradigm.save(sess.filePrefix.with_suffix(\".paradigm.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm.durations/3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect epochs\n",
    "Here we will various types of epochs which typical for hippocampal recordings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifacts epochs\n",
    "A typical session will have some artifacts that may negatively influence many analyses. Using a simple zscore measure, we can identify epochs where signal is above some threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import detect_artifact_epochs\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.core import Signal\n",
    "\n",
    "signal = sess.eegfile.get_signal([23,155])\n",
    "# filt_trace = signal_process.filter_sig.highpass(signal.traces,cutoff=400)\n",
    "# filtered_signal = Signal(np.median(filt_trace,axis=0).reshape((1,-1)),signal.sampling_rate)\n",
    "artifact_epochs = detect_artifact_epochs(signal, thresh=7)\n",
    "artifact_epochs.save(sess.filePrefix.with_suffix(\".artifact.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy import plotting\n",
    "signal = sess.eegfile.get_signal([23])\n",
    "# signal = Signal(filtered_signal.traces[0].reshape(1,-1),sampling_rate=1250)\n",
    "plotting.plot_artifact_epochs(sess.artifact, signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write artifact to neuroscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess.recinfo.write_epochs(sess.artifact,ext='.art')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write artifact epochs to spyking circus format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import SpykingCircusIO\n",
    "\n",
    "file = sess.filePrefix.with_suffix('.dead')\n",
    "SpykingCircusIO.write_epochs(file,sess.artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.t_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.signal_process import filter_sig\n",
    "\n",
    "sig = signal.time_slice(t_start=30,t_stop=40)\n",
    "\n",
    "yf = filter_sig.bandpass(sig.traces,lf=300,hf=600,fs=1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,signal.duration-5,3)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core import Signal\n",
    "from neuropy.analyses import brainstates\n",
    "\n",
    "signal = sess.eegfile.get_signal()\n",
    "brainstates = brainstates.detect_brainstates_epochs(\n",
    "    signal=signal, probe=sess.probegroup, window=5, overlap=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brainstates.filename = sess.filePrefix.with_suffix('.brainstates')\n",
    "brainstates.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ripple epochs\n",
    "To detect ripples one also needs probegroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import oscillations\n",
    "\n",
    "signal = sess.eegfile.get_signal()\n",
    "ripple_epochs = oscillations.detect_ripple_epochs(\n",
    "    signal=signal,\n",
    "    probegroup=sess.probegroup,\n",
    "    freq_band=(125, 250),\n",
    "    ignore_epochs=sess.artifact,\n",
    ")\n",
    "ripple_epochs.save(sess.filePrefix.with_suffix(\".ripple.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = sess.eegfile.get_signal(channel_id=[1, 2, 3, 4], t_start=1, t_stop=1.2)\n",
    "plotting.plot_signal_traces(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing spiketrains from Phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import PhyIO\n",
    "from neuropy.core import Neurons\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "cluster_path = Path(\n",
    "    \"/home/bapung/Documents/ClusteringHub/spykcirc/RatU/RatUDay1SD/RatU_Day1SD_2021-07-22_07-55-46-1.GUI\"\n",
    ")\n",
    "chan_grps = sess.recinfo.channel_groups\n",
    "phy_data = PhyIO(cluster_path)\n",
    "spiketrains = phy_data.spiketrains\n",
    "peak_chans = phy_data.peak_channels\n",
    "waveforms = phy_data.waveforms\n",
    "shank_id = sess.probegroup.get_shank_id_for_channels(peak_chans)\n",
    "\n",
    "neuron_type_id = phy_data.cluster_info.q.values\n",
    "neuron_type = np.ones(len(neuron_type_id), dtype=\"U5\")\n",
    "neuron_type[neuron_type_id < 4] = \"pyr\"\n",
    "neuron_type[neuron_type_id == 6] = \"mua\"\n",
    "neuron_type[neuron_type_id == 8] = \"inter\"\n",
    "\n",
    "\n",
    "neurons = Neurons(\n",
    "    np.array(spiketrains, dtype=object),\n",
    "    t_stop=sess.eegfile.duration,\n",
    "    sampling_rate=phy_data.sampling_rate,\n",
    "    peak_channels=peak_chans,\n",
    "    waveforms=np.array(waveforms, dtype=\"object\"),\n",
    "    shank_ids=np.array(shank_id).astype(int),\n",
    "    neuron_type=neuron_type,\n",
    "    metadata={\"cluster_path\": str(cluster_path)},\n",
    ")\n",
    "\n",
    "neurons.save(sess.filePrefix.with_suffix(\".neurons\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from neuropy.plotting import plot_raster\n",
    "\n",
    "\n",
    "plt.plot(phy_data.peak_waveforms[0])\n",
    "plot_raster(neurons,color='jet',add_vert_jitter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BinnedSpiketrain and Mua objects using Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mua =sess.neurons.get_mua()\n",
    "mua.save(sess.filePrefix.with_suffix(\".mua.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy import plotting\n",
    "smth_mua = sess.mua.get_smoothed(sigma=0.02)\n",
    "plotting.plot_mua(smth_mua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import detect_pbe_epochs\n",
    "\n",
    "pbe = detect_pbe_epochs(smth_mua)\n",
    "pbe.filename = sess.filePrefix.with_suffix('.pbe')\n",
    "pbe.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position\n",
    "- concatenated .dat file did not have any deleted timepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import position from optitrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import OptitrackIO\n",
    "from neuropy.core import Position\n",
    "from pathlib import Path\n",
    "\n",
    "opti_folder = sess.filePrefix.parent / 'position'\n",
    "opti_data = OptitrackIO(dirname=opti_folder,scale_factor=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align position with .dat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#---- startimes of concatenated .dat files\n",
    "tracking_sRate = opti_data.sampling_rate\n",
    "rec_datetime = pd.read_csv(sess.filePrefix.with_suffix('.datetime.csv'))\n",
    "data_time = []\n",
    "for i, file_time in enumerate(rec_datetime[\"startTime\"]):\n",
    "    # sync_time = rec_datetime['sync_nframes'][i]/rec_datetime['sync_rate'][i]\n",
    "    tbegin = datetime.strptime(file_time, \"%Y-%m-%d_%H-%M-%S\")\n",
    "    # + pd.Timedelta(sync_time,unit='sec')\n",
    "    nframes = rec_datetime[\"nFrames\"][i]\n",
    "    duration = pd.Timedelta(nframes / sess.recinfo.dat_sampling_rate, unit=\"sec\")\n",
    "    print(duration.total_seconds()*tracking_sRate)\n",
    "    tend = tbegin + duration\n",
    "    trange = pd.date_range(\n",
    "        start=tbegin,\n",
    "        end=tend,\n",
    "        periods=int(duration.total_seconds() * tracking_sRate),\n",
    "        # freq='16.66ms',\n",
    "        closed='left'\n",
    "    )\n",
    "    data_time.extend(trange)\n",
    "data_time = pd.to_datetime(data_time)\n",
    "\n",
    "x,y,z = opti_data.get_position_at_datetimes(data_time)\n",
    "traces = np.vstack((z,x,y))\n",
    "\n",
    "position = Position(traces=traces,t_start=0,sampling_rate=60)\n",
    "position.save(sess.filePrefix.with_suffix('.position'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_,ax = plt.subplots()\n",
    "\n",
    "ax.plot(position.x,position.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearize position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = sess.paradigm['maze'].flatten()\n",
    "maze_pos = sess.position.time_slice(maze[0],maze[1])\n",
    "linear_pos = position_util.linearize_position(maze_pos)\n",
    "linear_pos.save(sess.filePrefix.with_suffix('.maze.linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "plt.plot(maze_pos.time,maze_pos.x)\n",
    "plt.plot(linear_pos.time,linear_pos.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking position alignment with .dat file\n",
    "- Comparing theta power, speed and position to check if high theta periods are correlated with the speed of the animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy.utils import signal_process\n",
    "maze= sess.paradigm['maze']\n",
    "signal = sess.eegfile.get_signal([111],t_start=maze[0],t_stop=maze[1])\n",
    "# spec = signal_process.SpectrogramBands(signal,window=1,overlap=0.8,norm_sig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy_viewer import time_frequency_viewer\n",
    "\n",
    "time_frequency_viewer(signal,freq_params=(3,120,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils import signal_process\n",
    "from scipy import stats\n",
    "freqs = np.arange(1,20,0.5)\n",
    "wavdec = signal_process.wavelet_decomp(stats.zscore(signal.traces[0]),sampfreq=1250,freqs=freqs)\n",
    "\n",
    "wvlt_power = wavdec.colgin2009()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wvlt_power,aspect='auto',cmap='jet',vmax=80000,extent=[signal.t_start,signal.t_stop,wavdec.freqs[0],wavdec.freqs[-1]],origin='lower')\n",
    "plt.plot(pos_t,speed/10,'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = np.where((wavdec.freqs>=8)&(wavdec.freqs<=16))[0]\n",
    "theta_wvlt_power = np.median(wvlt_power[indx,:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "position = sess.position.time_slice(maze[0],maze[1])\n",
    "rpls = sess.ripple.time_slice(maze[0],maze[1]).starts\n",
    "x = position.x[:-1]\n",
    "y = position.y[:-1]\n",
    "pos_t = position.time[:-1]\n",
    "speed = gaussian_filter1d( position.speed,sigma =20)\n",
    "theta = np.interp(pos_t,spec.time,spec.theta)\n",
    "theta = gaussian_filter1d(theta,sigma=20)\n",
    "\n",
    "\n",
    "plt.plot(pos_t,theta*100,'r')\n",
    "# plt.plot(sess.position.time,sess.position.y)\n",
    "plt.plot(signal.time,theta_wvlt_power/4000,'r')\n",
    "plt.plot(rpls,100*np.ones_like(rpls),'*')\n",
    "plt.plot(pos_t,speed,'g')\n",
    "plt.plot(pos_t,x,'gray')\n",
    "plt.plot(pos_t,y,'gray')\n",
    "# plt.plot(pos_t,y,'k')\n",
    "# plt.plot(sess.position.time[1:],np.diff(sess.position.x)*100)\n",
    "# plt.xlim([1500,1600])\n",
    "plt.ylim([-400,400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position.filename = sess.filePrefix.with_suffix('.maze.linear')\n",
    "position.t_start = position.t_start +6\n",
    "position.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.paradigm['maze']/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import scipy.signal as sg\n",
    "\n",
    "xcorr = sg.correlate(theta,speed,mode='same')\n",
    "lags= sg.correlation_lags(len(pos_t),len(pos_t),mode='same')\n",
    "\n",
    "plt.plot(lags/position.sampling_rate,xcorr)\n",
    "# plt.xlim([-20,20])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3,7,8,9,10,15,16,17,18])\n",
    "y = np.array([6,7,8,9,10,11,12])\n",
    "z = np.array([2,3,2,5,6,3,4])\n",
    "plt.plot(x,np.ones_like(x),'.')\n",
    "plt.plot(y,2*np.ones_like(y),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.interp(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy.utils import position_util\n",
    "from neuropy.plotting import plot_epochs\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "run = position_util.run_direction(sess.lin_maze)\n",
    "run.filename = sess.filePrefix.with_suffix('.running')\n",
    "run.save()\n",
    "_,ax = plt.subplots()\n",
    "ax.plot(sess.lin_maze.time,sess.lin_maze.x)\n",
    "# ax.plot(sess.lin_maze.time,gaussian_filter1d(sess.lin_maze.x,sigma=50))\n",
    "plot_epochs(ax=ax,epochs=run,colors={'forward':'r','backward':'k'},alpha=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licking TTL epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import openephysio\n",
    "\n",
    "ttl_folder = '/data/Clustering/sessions/RatU/RatUDay2NSD/TTL_1' \n",
    "ttl = openephysio.load_ttl_events(ttl_folder,sync_info=False)\n",
    "print(ttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= '/data/Clustering/sessions/RatU/RatUDay2NSD/timestamps.npy'\n",
    "data = np.load(file)\n",
    "data[0]/30000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (ttl['timestamps']-985075968)/30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.eegfile.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.eegfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy.plotting import plot_epochs\n",
    "\n",
    "_,ax = plt.subplots()\n",
    "ax.plot(sess.position.time,sess.position.x)\n",
    "# plot_epochs(ax=ax,epochs= sess.paradigm)\n",
    "\n",
    "for val in b:\n",
    "    ax.axvline(val+45321,color='k')\n",
    "\n",
    "# ax.set_xlim(sess.paradigm['maze'])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce1618081139d19eb1ee8d40815d94a2de4f62e1efb20d9406ddb60628c36ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('data_analysis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
