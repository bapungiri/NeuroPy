{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read lick events from openephys events folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/data/Clustering/SleepDeprivation/RatS/Day2NSD/lick_events/\"\n",
    "p = Path(file)\n",
    "folders = [x for x in p.iterdir() if x.is_dir()]\n",
    "\n",
    "for folder in folders:\n",
    "    time = dateutil.parser.parse(folder.name, fuzzy=True)\n",
    "    print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create channel map for openephys in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = subjects.Sd().ratNday1[0]\n",
    "auxchans = sess.recinfo.auxchans\n",
    "chans = np.concatenate(sess.recinfo.channelgroups)\n",
    "chans = np.concatenate((chans, chans + 128, auxchans + 128, auxchans + 128 + 6))\n",
    "chan_map_oe = {\n",
    "    \"0\": {\n",
    "        \"mapping\": [int(_ + 1) for _ in chans],\n",
    "        \"reference\": [-1] * len(chans),\n",
    "        \"enabled\": [\"true\"] * len(chans),\n",
    "    },\n",
    "    \"refs\": {\"channels\": []},\n",
    "    \"recording\": {\"channels\": []},\n",
    "}\n",
    "with open(\"test_chanmap\", \"w\") as jfile:\n",
    "    json.dump(chan_map_oe, jfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ephyviewer for viewing ephys signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer import MainViewer, TraceViewer\n",
    "import numpy as np\n",
    "import subjects\n",
    "import pyqtgraph as pg\n",
    "\n",
    "# you must first create a main Qt application (for event loop)\n",
    "app = pg.mkQApp()\n",
    "\n",
    "# -------signals -----------\n",
    "sess = subjects.Sd().ratNday1[0]\n",
    "maze = sess.epochs.maze\n",
    "changrp = sess.recinfo.channelgroups[0]\n",
    "sigs = np.asarray(sess.recinfo.geteeg(chans=changrp, timeRange=maze))\n",
    "# sigs = sigs[:,np.newaxis]\n",
    "sigs = sigs.T\n",
    "sample_rate = float(sess.recinfo.lfpSrate)\n",
    "print(\"done\")\n",
    "# create fake 16 signals with 100000 at 10kHz\n",
    "# sigs = np.random.rand(400000,16)\n",
    "# sample_rate = 1250\n",
    "t_start = 0.0\n",
    "\n",
    "# Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# create a viewer for signal with TraceViewer\n",
    "# TraceViewer normally accept a AnalogSignalSource but\n",
    "# TraceViewer.from_numpy is facitilty function to bypass that\n",
    "view1 = TraceViewer.from_numpy(sigs, sample_rate, t_start, \"Signals\")\n",
    "\n",
    "# Parameters can be set in script\n",
    "view1.params[\"scale_mode\"] = \"same_for_all\"\n",
    "view1.params[\"display_labels\"] = True\n",
    "view1.params\n",
    "\n",
    "# And also parameters for each channel\n",
    "# view1.by_channel_params['ch0', 'visible'] = False\n",
    "# view1.by_channel_params['ch15', 'color'] = '#FF00AA'\n",
    "\n",
    "# This is needed when scale_mode='same_for_all'\n",
    "# to recompute the gain\n",
    "# this avoid to push auto_scale button\n",
    "view1.auto_scale()\n",
    "\n",
    "# put this veiwer in the main window\n",
    "win.add_view(view1)\n",
    "\n",
    "\n",
    "x = np.arange(1000)\n",
    "y = np.random.normal(size=(3, 1000))\n",
    "plotWidget = pg.plot(title=\"Three plot curves\")\n",
    "for i in range(3):\n",
    "    plotWidget.plot(x, y[i], pen=(i, 3))\n",
    "plotWidget.name = \"hl\"\n",
    "\n",
    "win.add_view(plotWidget)\n",
    "\n",
    "# show main window and run Qapp\n",
    "win.show()\n",
    "\n",
    "app.exec_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing sleep states editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ephyviewer also provides an epoch encoder which can be used with shortcut keys\n",
    "and/or the mouse to encode labels.\n",
    "\n",
    "ephyviewer makes available a CsvEpochSource class, which inherits from\n",
    "WritableEpochSource. If you would like to customize reading and writing epochs\n",
    "to files, you can write your own subclass of WritableEpochSource that implements\n",
    "the load() and save() methods.\n",
    "\n",
    "Here is an example of an epoch encoder that uses CsvEpochSource.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from ephyviewer import (\n",
    "    mkQApp,\n",
    "    MainViewer,\n",
    "    TraceViewer,\n",
    "    CsvEpochSource,\n",
    "    EpochViewer,\n",
    "    WritableEpochSource,\n",
    "    EpochEncoder,\n",
    "    SpikeTrainViewer,\n",
    "    TimeFreqViewer,\n",
    ")\n",
    "from ephyviewer import (\n",
    "    InMemoryEpochSource,\n",
    "    InMemorySpikeSource,\n",
    "    InMemoryAnalogSignalSource,\n",
    ")\n",
    "import numpy as np\n",
    "import subjects\n",
    "import os\n",
    "import pandas as pd\n",
    "import signal_process\n",
    "\n",
    "\n",
    "class statesSource(WritableEpochSource):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filename,\n",
    "        possible_labels,\n",
    "        color_labels=None,\n",
    "        channel_name=\"\",\n",
    "        restrict_to_possible_labels=False,\n",
    "    ):\n",
    "\n",
    "        self.filename = filename\n",
    "\n",
    "        WritableEpochSource.__init__(\n",
    "            self,\n",
    "            epoch=None,\n",
    "            possible_labels=possible_labels,\n",
    "            color_labels=color_labels,\n",
    "            channel_name=channel_name,\n",
    "            restrict_to_possible_labels=restrict_to_possible_labels,\n",
    "        )\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Returns a dictionary containing the data for an epoch.\n",
    "        Data is loaded from the CSV file if it exists; otherwise the superclass\n",
    "        implementation in WritableEpochSource.load() is called to create an\n",
    "        empty dictionary with the correct keys and types.\n",
    "        The method returns a dictionary containing the loaded data in this form:\n",
    "        { 'time': np.array, 'duration': np.array, 'label': np.array, 'name': string }\n",
    "        \"\"\"\n",
    "\n",
    "        if os.path.exists(self.filename):\n",
    "            # if file already exists, load previous epoch\n",
    "            data = pd.read_pickle(self.filename)\n",
    "            df = pd.DataFrame()\n",
    "            df[\"time\"] = data[\"start\"]\n",
    "            df[\"duration\"] = data[\"end\"] - data[\"start\"]\n",
    "            df[\"label\"] = \"U\"\n",
    "            # df = pd.read_csv(self.filename,  index_col=None, dtype={\n",
    "            #     'time':     'float64',\n",
    "            #     'duration': 'float64',\n",
    "            #     'label':    'U'})\n",
    "            state_number_dict = {\n",
    "                1: \"nrem\",\n",
    "                2: \"rem\",\n",
    "                3: \"quiet\",\n",
    "                4: \"active\",\n",
    "            }\n",
    "            data[\"name\"] = data[\"state\"].map(state_number_dict)\n",
    "\n",
    "            epoch_labels = np.array([f\" State{_}\" for _ in data[\"state\"]])\n",
    "            epoch = {\n",
    "                \"time\": data[\"start\"].values,\n",
    "                \"duration\": data[\"end\"].values - data[\"start\"].values,\n",
    "                \"label\": data[\"name\"],\n",
    "            }\n",
    "        else:\n",
    "            # if file does NOT already exist, use superclass method for creating\n",
    "            # an empty dictionary\n",
    "            epoch = super().load()\n",
    "\n",
    "        return epoch\n",
    "\n",
    "    def save(self):\n",
    "        # df = pd.DataFrame()\n",
    "        # df['time'] = np.round(self.ep_times, 6)         # round to nearest microsecond\n",
    "        # df['duration'] = np.round(self.ep_durations, 6) # round to nearest microsecond\n",
    "        # df['label'] = self.ep_labels\n",
    "        # df.sort_values(['time', 'duration', 'label'], inplace=True)\n",
    "        # df.to_pickle(self.filename)\n",
    "        df = pd.DataFrame()\n",
    "        df[\"start\"] = np.round(self.ep_times, 6)  # round to nearest microsecond\n",
    "        df[\"end\"] = np.round(self.ep_times, 6) + np.round(\n",
    "            self.ep_durations\n",
    "        )  # round to nearest microsecond\n",
    "        df[\"duration\"] = np.round(self.ep_durations, 6)  # round to nearest microsecond\n",
    "        state_number_dict = {\"nrem\": 1, \"rem\": 2, \"quiet\": 3, \"active\": 4}\n",
    "        df[\"name\"] = self.ep_labels\n",
    "        df[\"state\"] = df[\"name\"].map(state_number_dict)\n",
    "        df.sort_values([\"time\", \"duration\", \"name\"], inplace=True)\n",
    "        # df.to_pickle(self.filename)\n",
    "        np.save(self.filename, df)\n",
    "\n",
    "\n",
    "sess = subjects.Sd().ratNday1[0]\n",
    "# sleep_states = sess.brainstates.states\n",
    "filename = sess.brainstates.files.states\n",
    "\n",
    "\n",
    "# all_epochs = [{'time':sleep_states.start.values,'duration':sleep_states.duration.values,'label':sleep_states.name.to_numpy(),'name':'nrem'}]\n",
    "# source_ep = InMemoryEpochSource(all_epochs=all_epochs)\n",
    "possible_labels = [\"nrem\", \"rem\", \"quiet\", \"active\"]\n",
    "source_epoch = statesSource(str(filename), possible_labels)\n",
    "# lets encode some dev mood along the day\n",
    "\n",
    "# filename = 'example_dev_mood_encoder.csv'\n",
    "# source_epoch = CsvEpochSource(filename, possible_labels)\n",
    "\n",
    "\n",
    "# you must first create a main Qt application (for event loop)\n",
    "app = mkQApp()\n",
    "\n",
    "# create fake 16 signals with 100000 at 10kHz\n",
    "sigs = np.asarray(sess.recinfo.geteeg(chans=56)).reshape(-1, 1)\n",
    "filtered_sig = signal_process.filter_sig.bandpass(sigs, lf=120, hf=150, ax=0, fs=1250)\n",
    "sample_rate = sess.recinfo.lfpSrate\n",
    "t_start = 0.0\n",
    "\n",
    "# Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# create a viewer for signal\n",
    "view1 = TraceViewer.from_numpy(\n",
    "    np.hstack((sigs, filtered_sig)), sample_rate, t_start, \"Signals\"\n",
    ")\n",
    "view1.params[\"scale_mode\"] = \"same_for_all\"\n",
    "view1.auto_scale()\n",
    "win.add_view(view1)\n",
    "\n",
    "source_sig = InMemoryAnalogSignalSource(sigs, sample_rate, t_start)\n",
    "# create a viewer for the encoder itself\n",
    "view2 = EpochEncoder(source=source_epoch, name=\"Dev mood states along day\")\n",
    "win.add_view(view2)\n",
    "\n",
    "view3 = TimeFreqViewer(source=source_sig, name=\"tfr\")\n",
    "view3.params[\"show_axis\"] = False\n",
    "view3.params[\"timefreq\", \"deltafreq\"] = 1\n",
    "win.add_view(view3)\n",
    "\n",
    "\n",
    "# ----- spikes --------\n",
    "spikes = sess.spikes.pyr\n",
    "spk_id = sess.spikes.pyrid\n",
    "\n",
    "all_spikes = []\n",
    "for i, (t, id_) in enumerate(zip(spikes, spk_id)):\n",
    "    all_spikes.append({\"time\": t, \"name\": f\"Unit {i}\"})\n",
    "\n",
    "spike_source = InMemorySpikeSource(all_spikes=all_spikes)\n",
    "view4 = SpikeTrainViewer(source=spike_source)\n",
    "win.add_view(view4)\n",
    "# show main window and run Qapp\n",
    "win.show()\n",
    "\n",
    "\n",
    "app.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subjects\n",
    "from pyqtgraph import mkQApp\n",
    "\n",
    "app = mkQApp()\n",
    "sess = subjects.Sd().ratNday1[0]\n",
    "win = sess.brainstates.editor(chan=56)\n",
    "win.show()\n",
    "app.exec_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test epochs inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subjects\n",
    "\n",
    "sess = subjects.Sd().ratNday1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpls = sess.ripple.events\n",
    "file = np.load(sess.epochs.filename, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "file = (\n",
    "    \"/data/Clustering/SleepDeprivation/RatR/Day1NSD/RatRDay1NSD_2021-05-13_08-41-31.dat\"\n",
    ")\n",
    "data = np.memmap(file, dtype=\"int16\", mode=\"r\")\n",
    "data = np.memmap.reshape(data, (128, len(data) // 128), order=\"F\")\n",
    "\n",
    "data_chan = np.asarray(data[22, :][::24])\n",
    "\n",
    "# f, t, sxx = signal.stft(\n",
    "#     data_chan[-3600 * 1250 :], fs=1250, nperseg=5 * 1250, noverlap=2 * 1250\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "print(np.min(data_chan))\n",
    "# plt.pcolormesh(t,f,sxx,vmax=80000,shading='auto')\n",
    "# plt.ylim([0,50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, TimeFreqViewer\n",
    "from ephyviewer import InMemoryAnalogSignalSource\n",
    "import ephyviewer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# you must first create a main Qt application (for event loop)\n",
    "app = mkQApp()\n",
    "\n",
    "# create fake 16 signals with 100000 at 10kHz\n",
    "sigs = data_chan.reshape(-1, 1)\n",
    "sample_rate = 1250.0\n",
    "t_start = 0.0\n",
    "\n",
    "# Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# Create a datasource for the viewer\n",
    "# here we use InMemoryAnalogSignalSource but\n",
    "# you can alose use your custum datasource by inheritance\n",
    "source = InMemoryAnalogSignalSource(sigs, sample_rate, t_start)\n",
    "\n",
    "# create a viewer for signal with TraceViewer\n",
    "view1 = TraceViewer(source=source, name=\"trace\")\n",
    "view1.params[\"scale_mode\"] = \"same_for_all\"\n",
    "view1.auto_scale()\n",
    "\n",
    "# create a time freq viewer conencted to the same source\n",
    "view2 = TimeFreqViewer(source=source, name=\"tfr\")\n",
    "\n",
    "view2.params[\"show_axis\"] = False\n",
    "view2.params[\"timefreq\", \"deltafreq\"] = 1\n",
    "# view2.by_channel_params['ch3', 'visible'] = True\n",
    "\n",
    "\n",
    "# add them to mainwindow\n",
    "win.add_view(view1)\n",
    "win.add_view(view2)\n",
    "\n",
    "\n",
    "# show main window and run Qapp\n",
    "win.show()\n",
    "app.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import signal_process\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "fs = 2000\n",
    "time = np.arange(0, 0.5, 1.0 / fs)\n",
    "freq = np.ones(len(time)) * 100\n",
    "freq[int(len(time) * 0.4) : int(len(time) * 0.6)] = 180\n",
    "freq[int(len(time) * 0.7) : int(len(time) * 0.9)] = 260\n",
    "data = np.sin(2.0 * np.pi * freq * time)\n",
    "\n",
    "filt_data = signal_process.filter_sig.bandpass(data,lf=140,hf=250,fs=2000)\n",
    "\n",
    "plt.plot(time,stats.zscore(filt_data))\n",
    "\n",
    "# lfp = nept.LocalFieldPotential(data, time)\n",
    "\n",
    "# swrs = nept.detect_swr_hilbert(\n",
    "#     lfp,\n",
    "#     fs=2000,\n",
    "#     thresh=(140.0, 250.0),\n",
    "#     z_thresh=0.4,\n",
    "#     merge_thresh=0.02,\n",
    "#     min_length=0.01,\n",
    "# )\n",
    "\n",
    "# assert np.allclose(swrs.start, 0.1995)\n",
    "# assert np.allclose(swrs.stop, 0.301)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P:\n",
    "    def __init__(self,a=None,metadata=None,filename=None) -> None:\n",
    "        self.a = a\n",
    "        self.filename = filename;\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def a(self):\n",
    "        print('getter called')\n",
    "        return self._a\n",
    "\n",
    "    @a.setter\n",
    "    def a(self,a):\n",
    "        print('setter called')\n",
    "        self._a = a\n",
    "\n",
    "    \n",
    "    def load(self):\n",
    "        pass\n",
    "    def print_a(self):\n",
    "        print(self.a)\n",
    "    \n",
    "    def save(self):\n",
    "        pass\n",
    "    def myname(self):\n",
    "        print(self.filename)\n",
    "        \n",
    "class B(P):\n",
    "\n",
    "    def __init__(self,c) -> None:\n",
    "        self.filename = 'dfd'\n",
    "        self.c =c\n",
    "        super().__init__(None,self.filename)\n",
    "        # self.a = 7\n",
    "    \n",
    "    def detect(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subjects\n",
    "sess = subjects.Sd().ratNday1[0]\n",
    "sess.spindle.detect()\n",
    "# sess.spindle.freq_band\n",
    "# sess.spindle.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 20)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ModulesPath.core import Oscillation\n",
    "\n",
    "a = np.array([[1,10],[20,30]])\n",
    "\n",
    "b = np.concatenate([np.arange(start,stop) for (start,stop) in a])\n",
    "\n",
    "osc = Oscillation(freq_band=(5,20))\n",
    "osc.best_channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.arange(10)\n",
    "a[::-1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b10c821bc4bd3f433a613d47515e6babc6c2152896bd1e143404cc9d6ede4ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('data_analysis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}